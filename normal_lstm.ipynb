{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape, BatchNormalization, Add\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連x_test\n",
    "num_sample=100 #画像の総フレーム数\n",
    "timesteps=30 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "#画像関連\n",
    "channels=3\n",
    "img_width=50\n",
    "img_height=50\n",
    "\n",
    "# LSTMなどで用いる値\n",
    "n_hidden = 256    # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 5   # バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, camera_num, file_name, samples, timesteps, width, height):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=samples\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.learnData=[]\n",
    "        self.labelData=[]\n",
    "        self.make_image()\n",
    "        self.make_selection()\n",
    "    \n",
    "    def make_selection(self):\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        one_hot = np.eye(self.camera_num)\n",
    "        for row2 in csv_selection:\n",
    "            self.labelData.append(one_hot[int(row2[1])])\n",
    "    \n",
    "    def make_image(self):\n",
    "        for i in range(0, self.camera_num):\n",
    "            img_list=[]\n",
    "            print()\n",
    "            for j in range(0,self.samples):\n",
    "                #どのくらいデータロードが進んでいるか\n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/self.samples)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / self.samples * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "                file_path = \"image/\"+str(i)+\"/\"+str(j)+\".jpg\"\n",
    "                img = Image.open(file_path).convert('RGB') ## Gray->L, RGB->RGB\n",
    "                img = img.resize((self.width, self.height))\n",
    "                x = np.array(img, dtype=np.float32)\n",
    "                x = x / 255.\n",
    "                \n",
    "                img_list.append(x)\n",
    "            self.learnData.append(img_list)\n",
    "    \n",
    "    def make_image_by_video(self):\n",
    "        for i in range(0, self.camera_num):\n",
    "            img_list=[]\n",
    "            print()\n",
    "            video_path = self.file_name+\"video/\"+str(i)+\".mp4\"\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            self.samples = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            \n",
    "            for j in range(0,self.samples):\n",
    "                #どのくらいデータロードが進んでいるか\n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/self.samples)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / self.samples * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                img=Image.fromarray(frame)\n",
    "                img = img.resize((self.width, self.height))\n",
    "                x = np.array(img, dtype=np.float32)\n",
    "                x = x / 255.\n",
    "                \n",
    "                img_list.append(x)\n",
    "            self.learnData.append(img_list)\n",
    "    \n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        test=[]\n",
    "        for i in range(0,self.samples-self.timesteps):\n",
    "            tmp_list=[]\n",
    "            for j in range(0, self.timesteps):\n",
    "                tmp_list.append(self.learnData[num][i+j])\n",
    "            test.append(tmp_list)\n",
    "        tmp=np.array(test)\n",
    "        tmp=tmp.astype(np.float)\n",
    "                \n",
    "        return tmp\n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        test=[]\n",
    "        for i in range(self.timesteps,self.samples):\n",
    "            test.append(self.labelData[i])\n",
    "        tmp = np.array(test)\n",
    "        tmp = tmp.astype(np.float)\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def show(self):\n",
    "        print()\n",
    "        #print(self.get_learndata(0).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/5 [=================== ] 99.000000%\n",
      "2/5 [=================== ] 99.000000%\n",
      "3/5 [=================== ] 99.000000%\n",
      "4/5 [=================== ] 99.000000%\n",
      "5/5 [=================== ] 99.000000%\n",
      "(70, 5)\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(camera, \"./\", num_sample, timesteps, img_width, img_height)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18 :\n",
    "    ##\n",
    "    ##　Resnet-18の作成\n",
    "    ##\n",
    "    def __init__(self, width, height, channels):\n",
    "        self.img_rows=height\n",
    "        self.img_cols=width\n",
    "        self.img_channels=channels\n",
    "    \n",
    "    def rescell(self, data, filters, kernel_size, option=False):\n",
    "        strides=(1,1)\n",
    "        if option:\n",
    "            strides=(2,2)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        data=Convolution2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Add()([x,data])\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def create_resnet18(self):\n",
    "        inputs=Input(shape=(self.img_rows, self.img_cols, self.img_channels))\n",
    "        x=Convolution2D(64,(7,7), padding=\"same\", input_shape=(self.img_rows, self.img_cols),activation=\"relu\")(inputs)\n",
    "        x=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,128,(3,3),True)\n",
    "        x=self.rescell(x,128,(3,3))\n",
    "\n",
    "        x=self.rescell(x,256,(3,3),True)\n",
    "        x=self.rescell(x,256,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,512,(3,3),True)\n",
    "        x=self.rescell(x,512,(3,3))\n",
    "        \n",
    "        model=Model(inputs=inputs,outputs=[x])\n",
    "        return model\n",
    "\n",
    "    def get_resnet18(self):\n",
    "        return self.create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_hidden, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.resnet = Resnet18(width, height, 3).get_resnet18()\n",
    "        self.sharedLayer = self.create_sharedmodel()\n",
    "    \n",
    "    def create_sharedmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        x = TimeDistributed(self.resnet,name=\"resnet\")(inputs)\n",
    "        x = TimeDistributed(GlobalAveragePooling2D(), name=\"GAP\")(x)\n",
    "        x = TimeDistributed(Dense(512), name=\"dense\")(x)\n",
    "        predictions = LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, 35),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(x)\n",
    "        \n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_layers\")\n",
    "        \n",
    "        return shared_layers\n",
    "    \n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input2 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input3 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input4 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input5 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        mid_feature1 = self.sharedLayer(model_input1)\n",
    "        mid_feature2 = self.sharedLayer(model_input2)\n",
    "        mid_feature3 = self.sharedLayer(model_input3)\n",
    "        mid_feature4 = self.sharedLayer(model_input4)\n",
    "        mid_feature5 = self.sharedLayer(model_input5)\n",
    "        \n",
    "        merged_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=-1)\n",
    "        \n",
    "        mid_dense = Dense(self.n_hidden, activation='sigmoid')(merged_vector)\n",
    "        predictions = Dense(self.n_out, activation='sigmoid')(mid_dense)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], outputs=predictions)\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train1, x_train2, x_train3, x_train4, x_train5, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train1, x_train2, x_train3, x_train4, x_train5], t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "              shuffle = True, callbacks = [early_stopping], validation_split = 0.3)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 30, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 30, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 30, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 30, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 30, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_layers (Model)           (None, 256)          12668992    input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1280)         0           shared_layers[1][0]              \n",
      "                                                                 shared_layers[2][0]              \n",
      "                                                                 shared_layers[3][0]              \n",
      "                                                                 shared_layers[4][0]              \n",
      "                                                                 shared_layers[5][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          327936      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            1285        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,998,213\n",
      "Trainable params: 12,990,277\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 28s 568ms/step - loss: 0.2799 - acc: 0.8776 - val_loss: 0.4250 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.1301 - acc: 0.9755 - val_loss: 0.4040 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 0.1083 - acc: 0.9673 - val_loss: 0.3214 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 0.0928 - acc: 0.9755 - val_loss: 0.2655 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 6s 132ms/step - loss: 0.0684 - acc: 0.9918 - val_loss: 0.3183 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 6s 131ms/step - loss: 0.0810 - acc: 0.9755 - val_loss: 0.1831 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 7s 135ms/step - loss: 0.0586 - acc: 0.9796 - val_loss: 0.1760 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0535 - acc: 0.9837 - val_loss: 0.1491 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 6s 128ms/step - loss: 0.0557 - acc: 0.9755 - val_loss: 0.1677 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 0.0522 - acc: 0.9837 - val_loss: 0.1382 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 0.0445 - acc: 0.9918 - val_loss: 0.1799 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 6s 130ms/step - loss: 0.0473 - acc: 0.9878 - val_loss: 0.2059 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 7s 138ms/step - loss: 0.0534 - acc: 0.9755 - val_loss: 0.1782 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 6s 130ms/step - loss: 0.0397 - acc: 0.9918 - val_loss: 0.2393 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 0.0575 - acc: 0.9837 - val_loss: 0.0749 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "49/49 [==============================] - 6s 132ms/step - loss: 0.3363 - acc: 0.8653 - val_loss: 0.1279 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "49/49 [==============================] - 7s 133ms/step - loss: 0.1843 - acc: 0.9224 - val_loss: 0.0954 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "49/49 [==============================] - 7s 135ms/step - loss: 0.1045 - acc: 0.9673 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 0.1564 - acc: 0.9306 - val_loss: 0.1119 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 0.0444 - acc: 0.9918 - val_loss: 0.0777 - val_acc: 1.0000\n",
      "Epoch 00020: early stopping\n",
      "70/70 [==============================] - 3s 49ms/step\n",
      "score: [0.552480260176318, 0.7600000117506299]\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "正答率: 0.4\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "model , hist = pred.train(data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4), \n",
    "                                data.get_labeldata(), batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)], \n",
    "                                data.get_labeldata(), batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "pre = [[0 for i in range(5)] for j in range(5)]\n",
    "# 正答率集計\n",
    "preds = model.predict([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)])\n",
    "correct = 0\n",
    "\n",
    "f = open(\"./video/result.csv\", 'w')\n",
    "writer = csv.writer(f)\n",
    "for i in range(0,timesteps):\n",
    "    writer.writerow([0])\n",
    "        \n",
    "for i in range(len(preds)):\n",
    "    pred_result = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(data.get_labeldata()[i,:])\n",
    "    writer.writerow([pred_result])\n",
    "    pre[pred_result][tar]+=1\n",
    "    print(pred_result, tar)\n",
    "    if pred_result == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 4\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 0\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "正答率: 0.4\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "f = open(\"./video/result.csv\", 'w')\n",
    "writer = csv.writer(f)\n",
    "\n",
    "for i in range(0,timesteps):\n",
    "    writer.writerow([0])\n",
    "        \n",
    "for i in range(len(preds)):\n",
    "    pred_result = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(data.get_labeldata()[i,:])\n",
    "    writer.writerow([pred_result])\n",
    "    pre[pred_result][tar]+=1\n",
    "    print(pred_result, tar)\n",
    "    if pred_result == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
