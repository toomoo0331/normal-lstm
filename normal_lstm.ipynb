{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連x_test\n",
    "num_sample=100 #画像の総フレーム数\n",
    "timesteps=30 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "#画像関連\n",
    "channels=3\n",
    "img_width=100\n",
    "img_height=100\n",
    "\n",
    "# LSTMなどで用いる値\n",
    "n_hidden = 256    # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 5   # ミニバッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, camera_num, file_name, samples, timesteps, width, height):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=samples\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.learnData=[]\n",
    "        self.labelData=[]\n",
    "        \n",
    "        self.make_selection()\n",
    "        self.make_image()\n",
    "    \n",
    "    def make_selection(self):\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        one_hot = np.eye(self.camera_num)\n",
    "        for row2 in csv_selection:\n",
    "            self.labelData.append(one_hot[int(row2[1])])\n",
    "    \n",
    "    def make_image(self):\n",
    "        for i in range(0, self.camera_num):\n",
    "            img_list=[]\n",
    "            print()\n",
    "            for j in range(0,self.samples):\n",
    "                #どのくらいデータロードが進んでいるか\n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/self.samples)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / self.samples * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "                file_path = \"image/\"+str(i)+\"/\"+str(j)+\".jpg\"\n",
    "                img = Image.open(file_path).convert('RGB') ## Gray->L, RGB->RGB\n",
    "                img = img.resize((self.width, self.height))\n",
    "                x = np.array(img, dtype=np.float32)\n",
    "                x = x / 255.\n",
    "                \n",
    "                img_list.append(x)\n",
    "            self.learnData.append(img_list)\n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        test=[]\n",
    "        for i in range(0,self.samples-self.timesteps):\n",
    "            tmp_list=[]\n",
    "            for j in range(0, self.timesteps):\n",
    "                tmp_list.append(self.learnData[num][i+j])\n",
    "            test.append(tmp_list)\n",
    "        tmp=np.array(test)\n",
    "        tmp=tmp.astype(np.float)\n",
    "                \n",
    "        return tmp\n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        test=[]\n",
    "        for i in range(self.timesteps,self.samples):\n",
    "            test.append(self.labelData[i])\n",
    "        tmp = np.array(test)\n",
    "        tmp = tmp.astype(np.float)\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def show(self):\n",
    "        print()\n",
    "        #print(self.get_learndata(0).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/5 [=================== ] 99.000000%\n",
      "2/5 [=================== ] 99.000000%\n",
      "3/5 [=================== ] 99.000000%\n",
      "4/5 [=================== ] 99.000000%\n",
      "5/5 [=================== ] 99.000000%\n",
      "(70, 5)\n"
     ]
    }
   ],
   "source": [
    "data = Data(camera, \"./\", num_sample, timesteps, img_width, img_height)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet :\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _conv_bn_relu(self, nb_filter, nb_row, nb_col, subsample=(1, 1)):\n",
    "        def f(input):\n",
    "            conv = Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\")(input)\n",
    "            norm = BatchNormalization(mode=0, axis=1)(conv)\n",
    "            return Activation(\"relu\")(norm)\n",
    "        return f\n",
    "    \n",
    "    def _bn_relu_conv(self, nb_filter, nb_row, nb_col, subsample=(1, 1)):\n",
    "        def f(input):\n",
    "            norm = BatchNormalization(mode=0, axis=1)(input)\n",
    "            activation = Activation(\"relu\")(norm)\n",
    "            return Convolution2D(nb_filter=nb_filter, nb_row=nb_row, nb_col=nb_col, subsample=subsample,\n",
    "                                 init=\"he_normal\", border_mode=\"same\")(activation)\n",
    "        return f\n",
    "\n",
    "    def _basic_block(self, nb_filters, init_subsample=(1, 1)):\n",
    "        def f(input):\n",
    "            conv1 = _bn_relu_conv(nb_filters, 3, 3, subsample=init_subsample)(input)\n",
    "            residual = _bn_relu_conv(nb_filters, 3, 3)(conv1)\n",
    "            return _shortcut(input, residual)\n",
    "        return f\n",
    "\n",
    "    def _shortcut(self, input, residual):\n",
    "        stride_width = input._keras_shape[2] / residual._keras_shape[2]\n",
    "        stride_height = input._keras_shape[3] / residual._keras_shape[3]\n",
    "        equal_channels = residual._keras_shape[1] == input._keras_shape[1]\n",
    "\n",
    "        shortcut = input\n",
    "        if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "            shortcut = Convolution2D(nb_filter=residual._keras_shape[1], nb_row=1, nb_col=1,\n",
    "                                     subsample=(stride_width, stride_height),init=\"he_normal\", border_mode=\"valid\")(input)\n",
    "        return merge([shortcut, residual], mode=\"sum\")\n",
    "\n",
    "    def _residual_block(self, block_function, nb_filters, repetations, is_first_layer=False):\n",
    "        def f(input):\n",
    "            for i in range(repetations):\n",
    "                init_subsample = (1, 1)\n",
    "                if i == 0 and not is_first_layer:\n",
    "                    init_subsample = (2, 2)\n",
    "                    input = block_function(nb_filters=nb_filters, init_subsample=init_subsample)(input)\n",
    "            return input\n",
    "        return f\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.dot(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_hidden, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.resnet = Resnet()\n",
    "        self.sharedLayer = self.create_sharedmodel()\n",
    "    \n",
    "    def create_sharedmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        x = TimeDistributed(self.resnet._conv_bn_relu(nb_filter=64, nb_row=7, nb_col=7, subsample=(2, 2)))(inputs)\n",
    "        x = TimeDistributed(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode=\"same\"))(x)\n",
    "        block_fn = self.resnet._basic_block\n",
    "        x = TimeDistributed(self.resnet._residual_block(block_fn, nb_filter=64, repetations=3, is_first_layer=True))(x)\n",
    "        x = TimeDistributed(self.resnet._residual_block(block_fn, nb_filter=128, repetations=2))(x)\n",
    "        x = TimeDistributed(self.resnet._residual_block(block_fn, nb_filter=256, repetations=2))(x)\n",
    "        x = TimeDistributed(self.resnet._residual_block(block_fn, nb_filter=512, repetations=2))(x)\n",
    "        x = TimeDistributed(GlobalAveragePooling2D(pool_size=(7, 7), strides=(1, 1), border_mode=\"same\"), name=\"GAP\")(x)\n",
    "        x = TimeDistributed(Flatten())(x)\n",
    "        x = TimeDistributed(Dense(512), name=\"dense\")(x)\n",
    "        predictions = LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, 35),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(x)\n",
    "        #predictions = Dense(256, activation = \"softmax\", name=\"time_distr_dense_one\")(x)\n",
    "        \n",
    "        shared_layers = Network(inputs, predictions, name=\"shared_layers\")\n",
    "        return shared_layers\n",
    "    \n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input2 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input3 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input4 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input5 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        mid_feature1 = self.sharedLayer(model_input1)\n",
    "        mid_feature2 = self.sharedLayer(model_input2)\n",
    "        mid_feature3 = self.sharedLayer(model_input3)\n",
    "        mid_feature4 = self.sharedLayer(model_input4)\n",
    "        mid_feature5 = self.sharedLayer(model_input5)\n",
    "        \n",
    "        merged_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=-1)\n",
    "        \n",
    "        mid_dense = Dense(self.n_hidden, activation='sigmoid')(merged_vector)\n",
    "        predictions = Dense(self.n_out, activation='sigmoid')(mid_dense)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], outputs=predictions)\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train1, x_train2, x_train3, x_train4, x_train5, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train1, x_train2, x_train3, x_train4, x_train5], t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "              shuffle = True, callbacks = [early_stopping], validation_split = 0.3)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'built'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a035621ed376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-2280983a0eac>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, timesteps, n_hidden, n_out, width, height)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharedLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sharedmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_sharedmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-2280983a0eac>\u001b[0m in \u001b[0;36mcreate_sharedmodel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_bn_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mblock_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_basic_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mchild_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'built'"
     ]
    }
   ],
   "source": [
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "# 学習\n",
    "model , hist = pred.train(data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4), \n",
    "                                data.get_labeldata(), batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)], \n",
    "                                data.get_labeldata(), batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "pre = [[0 for i in range(3)] for j in range(3)]\n",
    "# 正答率集計\n",
    "preds = model.predict([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)])\n",
    "correct = 0\n",
    "for i in range(len(preds)):\n",
    "    pred = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(data.get_labeldata()[i,:])\n",
    "    pre[pred][tar]+=1\n",
    "    if pred == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
