{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape, BatchNormalization, Add\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連\n",
    "timesteps=10 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "rate = 5 #飛ばすフレーム数（30FPSを30/rateのFPSの動画に疑似変換する．）\n",
    "\n",
    "#画像関連 \n",
    "channels=3\n",
    "img_width=50\n",
    "img_height=50\n",
    "\n",
    "#LSTMなどで用いる値\n",
    "n_hidden = 256 # 出力次元 \n",
    "epochs = 100 # エポック数 \n",
    "batch_size = 5 # バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, camera_num, file_name, timesteps, width, height):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=0\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.save_numpy()\n",
    "        \n",
    "    def save_numpy(self):\n",
    "        self.samples = int(self.get_sample()/rate)\n",
    "        if not (os.path.isfile(self.file_name+\"label_\"+str(rate)+\".npy\")):\n",
    "            self.make_numpy_learnData()\n",
    "            self.make_numpy_labelData()\n",
    "        self.learnData=np.load(self.file_name+\"learn_\"+str(rate)+\".npy\")\n",
    "        self.labelData=np.load(self.file_name+\"label_\"+str(rate)+\".npy\")\n",
    "    \n",
    "    def get_sample(self):\n",
    "        video_path = self.file_name+\"video/0.mp4\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        num = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        return num\n",
    "    \n",
    "    def make_numpy_labelData(self):\n",
    "        labelData=[]\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        one_hot = np.eye(self.camera_num)\n",
    "        for i,row2 in enumerate(csv_selection):\n",
    "            if(i%rate==0 and i > (self.timesteps-1)*rate-1):\n",
    "                labelData.append(one_hot[int(row2[1])])\n",
    "        tmp_list = np.array(labelData)\n",
    "        tmp_list = tmp_list.astype(np.float)\n",
    "        np.save(self.file_name+\"label_\"+str(rate)+\".npy\", tmp_list)\n",
    "        print(tmp_list.shape)\n",
    "    \n",
    "    \n",
    "    def make_numpy_learnData(self):\n",
    "        learnData=[]\n",
    "        for i in range(0, self.camera_num):\n",
    "            print()\n",
    "            img_list=[]\n",
    "            video_path = self.file_name+\"video/\"+str(i)+\".mp4\"\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            for j in range(0,video_len):\n",
    "                \n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/video_len)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / video_len * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "                if(j%rate==0):\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    img=Image.fromarray(frame)\n",
    "                    img = img.resize((self.width, self.height))\n",
    "                    x = np.array(img, dtype=np.float32)\n",
    "                    x = x / 255.\n",
    "                    img_list.append(x)\n",
    "            learnData.append(img_list)\n",
    "            \n",
    "        tmp_list=np.array(learnData)\n",
    "        tmp_list=tmp_list.astype(np.float)\n",
    "        np.save(self.file_name+\"learn_\"+str(rate)+\".npy\", tmp_list)\n",
    "        print(tmp_list.shape)\n",
    "    \n",
    "    \n",
    "    def make_learndata(self, num=[]):\n",
    "        data_name=self.file_name+\"learn_0_\"+str(rate)+\".npy\"\n",
    "        if (os.path.isfile(data_name)):\n",
    "            test=np.load(data_name)\n",
    "        else:\n",
    "            all_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "            tmp_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "            for i in range(0, self.labelData.shape[0]):\n",
    "                #まずはすべての分だけ回す\n",
    "                pro_size=20\n",
    "                bar = int(i*pro_size/self.labelData.shape[0])\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(i / self.labelData.shape[0] * 100.)\n",
    "                print('\\r [{0}] {1}%'.format(pro_bar, percent), end='')\n",
    "                \n",
    "                count=num[np.argmax(self.labelData[i,:])]\n",
    "                \n",
    "                for j in range(0,count):\n",
    "                    #dataAugumentationする分だけ回す\n",
    "                    #dataAugmentationは異なるカメラでも同じ時間軸の場合同じ角度で回したいため，はじめに角度を取得する．\n",
    "                    random_angle = float(random.randint(0,180))\n",
    "                    \n",
    "                    for camera in range(0, self.camera_num):\n",
    "                        #カメラの台数だけ回す\n",
    "                        #tmp_list[camera]の同じ引数（番号）には角度を同じ分だけずらした同じ時間軸のsequenceが入っている．\n",
    "                        first_list =np.empty((0, self.width, self.height, 3), np.float)\n",
    "                        for l in range(0, self.timesteps):\n",
    "                            #timesteps分のndarrayを作る．\n",
    "                            tmp_img=self.learnData[camera,i+l]\n",
    "                            img = self.augumentation(tmp_img, random_angle)\n",
    "                            first_list =np.append(first_list, [img], axis=0)\n",
    "                        #あるカメラについて，１つのsequenceがfirst_listに出来上がっている状態．\n",
    "                        tmp_list[camera]=np.append(tmp_list[camera], [first_list], axis=0)\n",
    "                if(tmp_list[0].shape[0]>100 or i == self.labelData.shape[0]-1):\n",
    "                    #処理時間短縮のため，sequenceがtmp_listに溜まってきたら，全体に統合してまたtmp_listを初期化する．\n",
    "                    for camera in range(0, self.camera_num):\n",
    "                        all_list[camera]=np.append(all_list[camera], tmp_list[camera], axis=0)\n",
    "                        tmp_list[camera] = np.empty((0,self.timesteps, self.width, self.height, 3), np.float)\n",
    "            \n",
    "            for camera in range(0, self.camera_num):\n",
    "                print(all_list[camera].shape)\n",
    "                data_name=self.file_name+\"learn_\"+str(camera)+\"_\"+str(rate)\n",
    "                np.save(data_name, all_list[camera])\n",
    "                del all_list[camera]\n",
    "    \n",
    "    \n",
    "    def make_labeldata(self, num=[]):\n",
    "        data_name=self.file_name+\"final_label_\"+str(rate)+\"_.npy\"\n",
    "        if (os.path.isfile(data_name)):\n",
    "            test=np.load(data_name)\n",
    "        else:\n",
    "            test = np.empty((0,5), np.float)\n",
    "            for i in range(0,self.labelData.shape[0]):\n",
    "                count=num[np.argmax(self.labelData[i,:])]\n",
    "                for j in range(0, count):\n",
    "                    test = np.append(test, [self.labelData[i]], axis=0)\n",
    "            print(test.shape)\n",
    "            np.save(data_name, test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        data_name=self.file_name+\"learn_\"+str(num)+\"_\"+str(rate)+\".npy\"\n",
    "        test=np.load(data_name)\n",
    "        return test\n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        data_name=self.file_name+\"final_label_\"+str(rate)+\"_.npy\"\n",
    "        test=np.load(data_name)\n",
    "        return test\n",
    "    \n",
    "    \n",
    "    def augumentation(self, img, num):\n",
    "        height = img.shape[0]                \n",
    "        width = img.shape[1]                       \n",
    "        center = (int(width/2), int(height/2))\n",
    "        angle = num\n",
    "        scale = 1.0\n",
    "        trans = cv2.getRotationMatrix2D(center, angle , scale)\n",
    "        image2 = cv2.warpAffine(img, trans, (width,height))\n",
    "        return image2\n",
    "        \n",
    "    \n",
    "    def show(self):\n",
    "        print(0,self.get_learndata(0).shape)\n",
    "        print(1,self.get_learndata(1).shape)\n",
    "        print(2,self.get_learndata(2).shape)\n",
    "        print(3,self.get_learndata(3).shape)\n",
    "        print(4,self.get_learndata(4).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1687, 10, 50, 50, 3)\n",
      "1 (1687, 10, 50, 50, 3)\n",
      "2 (1687, 10, 50, 50, 3)\n",
      "3 (1687, 10, 50, 50, 3)\n",
      "4 (1687, 10, 50, 50, 3)\n",
      "(1687, 5)\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(camera, \"./data/20190426/\", timesteps, img_width, img_height)\n",
    "aug_rate=[3,7,7,2,1]\n",
    "data.make_learndata(aug_rate)\n",
    "data.make_labeldata(aug_rate)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18 :\n",
    "    ##\n",
    "    ##　Resnet-18の作成\n",
    "    ##\n",
    "    def __init__(self, width, height, channels):\n",
    "        self.img_rows=height\n",
    "        self.img_cols=width\n",
    "        self.img_channels=channels\n",
    "    \n",
    "    def rescell(self, data, filters, kernel_size, option=False):\n",
    "        strides=(1,1)\n",
    "        if option:\n",
    "            strides=(2,2)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        data=Convolution2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Add()([x,data])\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def create_resnet18(self):\n",
    "        inputs=Input(shape=(self.img_rows, self.img_cols, self.img_channels))\n",
    "        x=Convolution2D(64,(7,7), padding=\"same\", input_shape=(self.img_rows, self.img_cols),activation=\"relu\")(inputs)\n",
    "        x=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,128,(3,3),True)\n",
    "        x=self.rescell(x,128,(3,3))\n",
    "\n",
    "        x=self.rescell(x,256,(3,3),True)\n",
    "        x=self.rescell(x,256,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,512,(3,3),True)\n",
    "        x=self.rescell(x,512,(3,3))\n",
    "        \n",
    "        model=Model(inputs=inputs,outputs=[x])\n",
    "        return model\n",
    "\n",
    "    def get_resnet18(self):\n",
    "        return self.create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_hidden, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.resnet = Resnet18(width, height, 3).get_resnet18()\n",
    "        self.sharedLayer = self.create_sharedmodel()\n",
    "    \n",
    "    def create_sharedmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        x = TimeDistributed(self.resnet,name=\"resnet\")(inputs)\n",
    "        x = TimeDistributed(GlobalAveragePooling2D(), name=\"GAP\")(x)\n",
    "        x = TimeDistributed(Dense(512), name=\"dense\")(x)\n",
    "        predictions = LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, 35),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(x)\n",
    "        \n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_layers\")\n",
    "        \n",
    "        return shared_layers\n",
    "    \n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input2 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input3 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input4 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input5 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        mid_feature1 = self.sharedLayer(model_input1)\n",
    "        mid_feature2 = self.sharedLayer(model_input2)\n",
    "        mid_feature3 = self.sharedLayer(model_input3)\n",
    "        mid_feature4 = self.sharedLayer(model_input4)\n",
    "        mid_feature5 = self.sharedLayer(model_input5)\n",
    "        \n",
    "        merged_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=-1)\n",
    "        \n",
    "        mid_dense = Dense(self.n_hidden, activation='sigmoid')(merged_vector)\n",
    "        predictions = Dense(self.n_out, activation='sigmoid')(mid_dense)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], outputs=predictions)\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train, t_train, x_vali, t_vali batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train[0], x_train[1], x_train[2], x_train[3], x_train[4]], t_train, batch_size = batch_size, epochs = epochs, \n",
    "                         validation_data=([x_vali[0], x_vali[1], x_vali[2], x_vali[3], x_vali[4]], t_vali), shuffle = True, callbacks = [early_stopping], validation_split = 0.1)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_layers (Model)           (None, 256)          12668992    input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1280)         0           shared_layers[1][0]              \n",
      "                                                                 shared_layers[2][0]              \n",
      "                                                                 shared_layers[3][0]              \n",
      "                                                                 shared_layers[4][0]              \n",
      "                                                                 shared_layers[5][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          327936      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            1285        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,998,213\n",
      "Trainable params: 12,990,277\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1518 samples, validate on 169 samples\n",
      "Epoch 1/100\n",
      "1518/1518 [==============================] - 107s 71ms/step - loss: 0.4749 - acc: 0.7978 - val_loss: 0.5388 - val_acc: 0.7160\n",
      "Epoch 2/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.4482 - acc: 0.8084 - val_loss: 0.5315 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "1518/1518 [==============================] - 77s 50ms/step - loss: 0.4019 - acc: 0.8207 - val_loss: 0.5346 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.3165 - acc: 0.8606 - val_loss: 0.6645 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "1518/1518 [==============================] - 81s 54ms/step - loss: 0.2663 - acc: 0.8813 - val_loss: 0.7362 - val_acc: 0.7160\n",
      "Epoch 6/100\n",
      "1518/1518 [==============================] - 81s 53ms/step - loss: 0.2314 - acc: 0.9012 - val_loss: 0.6906 - val_acc: 0.8000\n",
      "Epoch 7/100\n",
      "1518/1518 [==============================] - 81s 53ms/step - loss: 0.1935 - acc: 0.9209 - val_loss: 0.9575 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "1518/1518 [==============================] - 80s 53ms/step - loss: 0.1612 - acc: 0.9352 - val_loss: 1.4190 - val_acc: 0.8000\n",
      "Epoch 9/100\n",
      "1518/1518 [==============================] - 81s 54ms/step - loss: 0.1283 - acc: 0.9506 - val_loss: 1.1780 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "1518/1518 [==============================] - 80s 52ms/step - loss: 0.1118 - acc: 0.9549 - val_loss: 1.3014 - val_acc: 0.8000\n",
      "Epoch 11/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.1025 - acc: 0.9597 - val_loss: 1.5693 - val_acc: 0.8000\n",
      "Epoch 12/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.0870 - acc: 0.9659 - val_loss: 1.6380 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "1518/1518 [==============================] - 78s 51ms/step - loss: 0.0854 - acc: 0.9671 - val_loss: 1.7867 - val_acc: 0.6592\n",
      "Epoch 14/100\n",
      "1518/1518 [==============================] - 80s 53ms/step - loss: 0.0757 - acc: 0.9713 - val_loss: 1.8242 - val_acc: 0.8000\n",
      "Epoch 15/100\n",
      "1518/1518 [==============================] - 78s 52ms/step - loss: 0.0715 - acc: 0.9709 - val_loss: 1.6405 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.0616 - acc: 0.9767 - val_loss: 1.6336 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.0609 - acc: 0.9775 - val_loss: 2.0031 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.0555 - acc: 0.9819 - val_loss: 2.2602 - val_acc: 0.6592\n",
      "Epoch 19/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.0460 - acc: 0.9833 - val_loss: 2.1661 - val_acc: 0.6592\n",
      "Epoch 20/100\n",
      "1518/1518 [==============================] - 80s 53ms/step - loss: 0.0596 - acc: 0.9784 - val_loss: 2.0596 - val_acc: 0.8000\n",
      "Epoch 21/100\n",
      "1518/1518 [==============================] - 80s 53ms/step - loss: 0.0504 - acc: 0.9829 - val_loss: 1.9457 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "1518/1518 [==============================] - 79s 52ms/step - loss: 0.0402 - acc: 0.9852 - val_loss: 1.9021 - val_acc: 0.8000\n",
      "Epoch 00022: early stopping\n",
      "1687/1687 [==============================] - 32s 19ms/step\n",
      "score: [1.570456019999646, 0.800000011920929]\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 1\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 3\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 0\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "4 2\n",
      "正答率: 0.21280379371665678\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "test_learn=[np.empty((data.get_labeldata().shape[0],10, 50, 50, 3), np.float)]*camera\n",
    "vali_learn=[np.empty((0,10, 50, 50, 3), np.float)]*camera\n",
    "test_label=data.get_labeldata()\n",
    "vali_label=np.empty((0,camera), np.float)\n",
    "\n",
    "print(test_label.shape)\n",
    "\n",
    "for j in range(0,camera):\n",
    "    test_learn[j]=data.get_learndata(j)\n",
    "\n",
    "for i in tqdm(range(0,int(0.1*test_label.shape[0]))):\n",
    "    random_angle = int(random.randint(0,test_label.shape[0]-1))\n",
    "    for j in range(0,camera):\n",
    "        vali_learn[j]=np.append(vali_learn[j], [test_learn[j][random_angle]],axis=0)\n",
    "        test_learn[j]=np.delete(test_learn[j], random_angle,0)\n",
    "    vali_label=np.append(vali_label, [test_label[random_angle]], axis=0)\n",
    "    test_label=np.delete(test_label, random_angle,0)\n",
    "\n",
    "\n",
    "\n",
    "# 学習\n",
    "model , hist = pred.train(test_learn, test_label, vali_learn, vali_label, batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate(test_learn, test_label, batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "#                            モデルのアーキテクチャの保存\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# モデルのアーキテクチャの保存①(JSON版)\n",
    "model_arc_json = model.to_json()\n",
    "open(\"model_architecture.json\", mode='w').write(model_arc_json)\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "#                            　　モデルの重みの保存\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "# モデルの重みの保存\n",
    "model.save_weights(\"weights.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#試すやつ！\n",
    "\n",
    "pre = [[0 for i in range(5)] for j in range(5)]\n",
    "# 正答率集計\n",
    "preds = model.predict([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)])\n",
    "correct = 0\n",
    "\n",
    "f = open(\"./data/20190426/result.csv\", 'w')\n",
    "writer = csv.writer(f)\n",
    "for i in range(0,timesteps):\n",
    "    writer.writerow([0])\n",
    "        \n",
    "for i in range(len(preds)):\n",
    "    pred_result = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(data.get_labeldata()[i,:])\n",
    "    for j in range(0,rate):\n",
    "        writer.writerow([pred_result])\n",
    "    pre[pred_result][tar]+=1\n",
    "    print(pred_result, tar)\n",
    "    if pred_result == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 50, 43, 193, 359]\n"
     ]
    }
   ],
   "source": [
    "a = [0,0,0,0,0]\n",
    "for i in range(0, 742):\n",
    "    tar = np.argmax(data.get_labeldata()[i,:])\n",
    "    a[tar]=a[tar]+1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1687, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/168 [00:02<06:41,  2.40s/it]\u001b[A\n",
      "  1%|          | 2/168 [00:04<06:37,  2.40s/it]\u001b[A\n",
      "  2%|▏         | 3/168 [00:07<06:34,  2.39s/it]\u001b[A\n",
      "  2%|▏         | 4/168 [00:09<06:30,  2.38s/it]\u001b[A\n",
      "  3%|▎         | 5/168 [00:11<06:29,  2.39s/it]\u001b[A\n",
      "  4%|▎         | 6/168 [00:14<06:27,  2.39s/it]\u001b[A\n",
      "  4%|▍         | 7/168 [00:16<06:24,  2.39s/it]\u001b[A\n",
      "  5%|▍         | 8/168 [00:19<06:23,  2.40s/it]\u001b[A\n",
      "  5%|▌         | 9/168 [00:21<06:20,  2.39s/it]\u001b[A\n",
      "  6%|▌         | 10/168 [00:23<06:17,  2.39s/it]\u001b[A\n",
      "  7%|▋         | 11/168 [00:26<06:13,  2.38s/it]\u001b[A\n",
      "  7%|▋         | 12/168 [00:28<06:16,  2.41s/it]\u001b[A\n",
      "  8%|▊         | 13/168 [00:31<06:13,  2.41s/it]\u001b[A\n",
      "  8%|▊         | 14/168 [00:33<06:09,  2.40s/it]\u001b[A\n",
      "  9%|▉         | 15/168 [00:35<06:06,  2.40s/it]\u001b[A\n",
      " 10%|▉         | 16/168 [00:38<06:10,  2.44s/it]\u001b[A\n",
      " 10%|█         | 17/168 [00:40<06:05,  2.42s/it]\u001b[A\n",
      " 11%|█         | 18/168 [00:43<06:01,  2.41s/it]\u001b[A\n",
      " 11%|█▏        | 19/168 [00:45<05:57,  2.40s/it]\u001b[A\n",
      " 12%|█▏        | 20/168 [00:47<05:53,  2.39s/it]\u001b[A\n",
      " 12%|█▎        | 21/168 [00:50<05:50,  2.38s/it]\u001b[A\n",
      " 13%|█▎        | 22/168 [00:52<05:47,  2.38s/it]\u001b[A\n",
      " 14%|█▎        | 23/168 [00:55<05:43,  2.37s/it]\u001b[A\n",
      " 14%|█▍        | 24/168 [00:57<05:40,  2.36s/it]\u001b[A\n",
      " 15%|█▍        | 25/168 [00:59<05:37,  2.36s/it]\u001b[A\n",
      " 15%|█▌        | 26/168 [01:02<05:35,  2.36s/it]\u001b[A\n",
      " 16%|█▌        | 27/168 [01:04<05:32,  2.36s/it]\u001b[A\n",
      " 17%|█▋        | 28/168 [01:06<05:29,  2.36s/it]\u001b[A\n",
      " 17%|█▋        | 29/168 [01:09<05:29,  2.37s/it]\u001b[A\n",
      " 18%|█▊        | 30/168 [01:11<05:26,  2.37s/it]\u001b[A\n",
      " 18%|█▊        | 31/168 [01:13<05:24,  2.36s/it]\u001b[A\n",
      " 19%|█▉        | 32/168 [01:16<05:21,  2.36s/it]\u001b[A\n",
      " 20%|█▉        | 33/168 [01:18<05:18,  2.36s/it]\u001b[A\n",
      " 20%|██        | 34/168 [01:20<05:15,  2.35s/it]\u001b[A\n",
      " 21%|██        | 35/168 [01:23<05:13,  2.36s/it]\u001b[A\n",
      " 21%|██▏       | 36/168 [01:25<05:11,  2.36s/it]\u001b[A\n",
      " 22%|██▏       | 37/168 [01:28<05:08,  2.36s/it]\u001b[A\n",
      " 23%|██▎       | 38/168 [01:30<05:05,  2.35s/it]\u001b[A\n",
      " 23%|██▎       | 39/168 [01:32<05:02,  2.35s/it]\u001b[A\n",
      " 24%|██▍       | 40/168 [01:35<05:06,  2.40s/it]\u001b[A\n",
      " 24%|██▍       | 41/168 [01:37<05:04,  2.40s/it]\u001b[A\n",
      " 25%|██▌       | 42/168 [01:40<05:02,  2.40s/it]\u001b[A\n",
      " 26%|██▌       | 43/168 [01:42<04:59,  2.40s/it]\u001b[A\n",
      " 26%|██▌       | 44/168 [01:44<04:56,  2.39s/it]\u001b[A\n",
      " 27%|██▋       | 45/168 [01:47<04:54,  2.40s/it]\u001b[A\n",
      " 27%|██▋       | 46/168 [01:49<04:52,  2.40s/it]\u001b[A\n",
      " 28%|██▊       | 47/168 [01:52<04:50,  2.40s/it]\u001b[A\n",
      " 29%|██▊       | 48/168 [01:54<04:47,  2.40s/it]\u001b[A\n",
      " 29%|██▉       | 49/168 [01:56<04:45,  2.40s/it]\u001b[A\n",
      " 30%|██▉       | 50/168 [01:59<04:42,  2.40s/it]\u001b[A\n",
      " 30%|███       | 51/168 [02:01<04:39,  2.39s/it]\u001b[A\n",
      " 31%|███       | 52/168 [02:03<04:37,  2.39s/it]\u001b[A\n",
      " 32%|███▏      | 53/168 [02:06<04:34,  2.39s/it]\u001b[A\n",
      " 32%|███▏      | 54/168 [02:08<04:33,  2.40s/it]\u001b[A\n",
      " 33%|███▎      | 55/168 [02:11<04:33,  2.42s/it]\u001b[A\n",
      " 33%|███▎      | 56/168 [02:13<04:30,  2.41s/it]\u001b[A\n",
      " 34%|███▍      | 57/168 [02:16<04:27,  2.41s/it]\u001b[A\n",
      " 35%|███▍      | 58/168 [02:18<04:24,  2.41s/it]\u001b[A\n",
      " 35%|███▌      | 59/168 [02:20<04:22,  2.41s/it]\u001b[A\n",
      " 36%|███▌      | 60/168 [02:23<04:21,  2.42s/it]\u001b[A\n",
      " 36%|███▋      | 61/168 [02:25<04:19,  2.42s/it]\u001b[A\n",
      " 37%|███▋      | 62/168 [02:28<04:19,  2.45s/it]\u001b[A\n",
      " 38%|███▊      | 63/168 [02:30<04:16,  2.44s/it]\u001b[A\n",
      " 38%|███▊      | 64/168 [02:33<04:12,  2.43s/it]\u001b[A\n",
      " 39%|███▊      | 65/168 [02:35<04:09,  2.42s/it]\u001b[A\n",
      " 39%|███▉      | 66/168 [02:37<04:07,  2.42s/it]\u001b[A\n",
      " 40%|███▉      | 67/168 [02:40<04:04,  2.42s/it]\u001b[A\n",
      " 40%|████      | 68/168 [02:42<04:01,  2.42s/it]\u001b[A\n",
      " 41%|████      | 69/168 [02:45<03:59,  2.42s/it]\u001b[A\n",
      " 42%|████▏     | 70/168 [02:47<03:59,  2.44s/it]\u001b[A\n",
      " 42%|████▏     | 71/168 [02:50<03:56,  2.44s/it]\u001b[A\n",
      " 43%|████▎     | 72/168 [02:52<03:54,  2.45s/it]\u001b[A\n",
      " 43%|████▎     | 73/168 [02:55<03:55,  2.48s/it]\u001b[A\n",
      " 44%|████▍     | 74/168 [02:57<03:50,  2.45s/it]\u001b[A\n",
      " 45%|████▍     | 75/168 [02:59<03:47,  2.44s/it]\u001b[A\n",
      " 45%|████▌     | 76/168 [03:02<03:47,  2.47s/it]\u001b[A\n",
      " 46%|████▌     | 77/168 [03:04<03:43,  2.46s/it]\u001b[A\n",
      " 46%|████▋     | 78/168 [03:07<03:40,  2.45s/it]\u001b[A\n",
      " 47%|████▋     | 79/168 [03:09<03:37,  2.45s/it]\u001b[A\n",
      " 48%|████▊     | 80/168 [03:12<03:35,  2.44s/it]\u001b[A\n",
      " 48%|████▊     | 81/168 [03:14<03:32,  2.44s/it]\u001b[A\n",
      " 49%|████▉     | 82/168 [03:17<03:29,  2.44s/it]\u001b[A\n",
      " 49%|████▉     | 83/168 [03:19<03:30,  2.48s/it]\u001b[A\n",
      " 50%|█████     | 84/168 [03:22<03:27,  2.47s/it]\u001b[A\n",
      " 51%|█████     | 85/168 [03:24<03:24,  2.46s/it]\u001b[A\n",
      " 51%|█████     | 86/168 [03:26<03:20,  2.45s/it]\u001b[A\n",
      " 52%|█████▏    | 87/168 [03:29<03:17,  2.44s/it]\u001b[A\n",
      " 52%|█████▏    | 88/168 [03:31<03:17,  2.47s/it]\u001b[A\n",
      " 53%|█████▎    | 89/168 [03:34<03:13,  2.45s/it]\u001b[A\n",
      " 54%|█████▎    | 90/168 [03:36<03:10,  2.44s/it]\u001b[A\n",
      " 54%|█████▍    | 91/168 [03:39<03:09,  2.46s/it]\u001b[A\n",
      " 55%|█████▍    | 92/168 [03:41<03:06,  2.46s/it]\u001b[A\n",
      " 55%|█████▌    | 93/168 [03:44<03:03,  2.45s/it]\u001b[A\n",
      " 56%|█████▌    | 94/168 [03:46<03:04,  2.49s/it]\u001b[A\n",
      " 57%|█████▋    | 95/168 [03:49<03:02,  2.51s/it]\u001b[A\n",
      " 57%|█████▋    | 96/168 [03:51<02:59,  2.49s/it]\u001b[A\n",
      " 58%|█████▊    | 97/168 [03:54<02:55,  2.47s/it]\u001b[A\n",
      " 58%|█████▊    | 98/168 [03:56<02:53,  2.47s/it]\u001b[A\n",
      " 59%|█████▉    | 99/168 [03:59<02:53,  2.51s/it]\u001b[A\n",
      " 60%|█████▉    | 100/168 [04:01<02:49,  2.49s/it]\u001b[A\n",
      " 60%|██████    | 101/168 [04:04<02:45,  2.47s/it]\u001b[A\n",
      " 61%|██████    | 102/168 [04:06<02:42,  2.46s/it]\u001b[A\n",
      " 61%|██████▏   | 103/168 [04:08<02:39,  2.45s/it]\u001b[A\n",
      " 62%|██████▏   | 104/168 [04:11<02:35,  2.44s/it]\u001b[A\n",
      " 62%|██████▎   | 105/168 [04:13<02:33,  2.43s/it]\u001b[A\n",
      " 63%|██████▎   | 106/168 [04:16<02:30,  2.43s/it]\u001b[A\n",
      " 64%|██████▎   | 107/168 [04:18<02:28,  2.43s/it]\u001b[A\n",
      " 64%|██████▍   | 108/168 [04:21<02:25,  2.42s/it]\u001b[A\n",
      " 65%|██████▍   | 109/168 [04:23<02:22,  2.42s/it]\u001b[A\n",
      " 65%|██████▌   | 110/168 [04:25<02:20,  2.41s/it]\u001b[A\n",
      " 66%|██████▌   | 111/168 [04:28<02:17,  2.42s/it]\u001b[A\n",
      " 67%|██████▋   | 112/168 [04:30<02:15,  2.42s/it]\u001b[A\n",
      " 67%|██████▋   | 113/168 [04:33<02:14,  2.44s/it]\u001b[A\n",
      " 68%|██████▊   | 114/168 [04:35<02:11,  2.44s/it]\u001b[A\n",
      " 68%|██████▊   | 115/168 [04:38<02:09,  2.44s/it]\u001b[A\n",
      " 69%|██████▉   | 116/168 [04:40<02:06,  2.43s/it]\u001b[A\n",
      " 70%|██████▉   | 117/168 [04:42<02:04,  2.44s/it]\u001b[A\n",
      " 70%|███████   | 118/168 [04:45<02:03,  2.47s/it]\u001b[A\n",
      " 71%|███████   | 119/168 [04:47<02:00,  2.46s/it]\u001b[A\n",
      " 71%|███████▏  | 120/168 [04:50<01:59,  2.49s/it]\u001b[A\n",
      " 72%|███████▏  | 121/168 [04:52<01:56,  2.48s/it]\u001b[A\n",
      " 73%|███████▎  | 122/168 [04:55<01:53,  2.46s/it]\u001b[A\n",
      " 73%|███████▎  | 123/168 [04:57<01:50,  2.45s/it]\u001b[A\n",
      " 74%|███████▍  | 124/168 [05:00<01:46,  2.43s/it]\u001b[A\n",
      " 74%|███████▍  | 125/168 [05:02<01:44,  2.42s/it]\u001b[A\n",
      " 75%|███████▌  | 126/168 [05:04<01:41,  2.42s/it]\u001b[A\n",
      " 76%|███████▌  | 127/168 [05:07<01:39,  2.42s/it]\u001b[A\n",
      " 76%|███████▌  | 128/168 [05:09<01:36,  2.41s/it]\u001b[A\n",
      " 77%|███████▋  | 129/168 [05:12<01:34,  2.41s/it]\u001b[A\n",
      " 77%|███████▋  | 130/168 [05:14<01:31,  2.41s/it]\u001b[A\n",
      " 78%|███████▊  | 131/168 [05:17<01:29,  2.42s/it]\u001b[A\n",
      " 79%|███████▊  | 132/168 [05:19<01:27,  2.42s/it]\u001b[A\n",
      " 79%|███████▉  | 133/168 [05:21<01:24,  2.42s/it]\u001b[A\n",
      " 80%|███████▉  | 134/168 [05:24<01:22,  2.43s/it]\u001b[A\n",
      " 80%|████████  | 135/168 [05:26<01:21,  2.47s/it]\u001b[A\n",
      " 81%|████████  | 136/168 [05:29<01:18,  2.46s/it]\u001b[A\n",
      " 82%|████████▏ | 137/168 [05:31<01:15,  2.45s/it]\u001b[A\n",
      " 82%|████████▏ | 138/168 [05:34<01:13,  2.44s/it]\u001b[A\n",
      " 83%|████████▎ | 139/168 [05:36<01:10,  2.44s/it]\u001b[A\n",
      " 83%|████████▎ | 140/168 [05:39<01:08,  2.45s/it]\u001b[A\n",
      " 84%|████████▍ | 141/168 [05:41<01:06,  2.45s/it]\u001b[A\n",
      " 85%|████████▍ | 142/168 [05:43<01:03,  2.44s/it]\u001b[A\n",
      " 85%|████████▌ | 143/168 [05:46<01:00,  2.44s/it]\u001b[A\n",
      " 86%|████████▌ | 144/168 [05:48<00:58,  2.44s/it]\u001b[A\n",
      " 86%|████████▋ | 145/168 [05:51<00:57,  2.51s/it]\u001b[A\n",
      " 87%|████████▋ | 146/168 [05:53<00:54,  2.50s/it]\u001b[A\n",
      " 88%|████████▊ | 147/168 [05:56<00:53,  2.53s/it]\u001b[A\n",
      " 88%|████████▊ | 148/168 [05:58<00:50,  2.50s/it]\u001b[A\n",
      " 89%|████████▊ | 149/168 [06:01<00:48,  2.53s/it]\u001b[A\n",
      " 89%|████████▉ | 150/168 [06:04<00:45,  2.50s/it]\u001b[A\n",
      " 90%|████████▉ | 151/168 [06:06<00:42,  2.48s/it]\u001b[A\n",
      " 90%|█████████ | 152/168 [06:08<00:39,  2.46s/it]\u001b[A\n",
      " 91%|█████████ | 153/168 [06:11<00:36,  2.45s/it]\u001b[A\n",
      " 92%|█████████▏| 154/168 [06:13<00:34,  2.45s/it]\u001b[A\n",
      " 92%|█████████▏| 155/168 [06:16<00:32,  2.50s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 156/168 [06:18<00:29,  2.48s/it]\u001b[A\n",
      " 93%|█████████▎| 157/168 [06:21<00:27,  2.48s/it]\u001b[A\n",
      " 94%|█████████▍| 158/168 [06:23<00:24,  2.47s/it]\u001b[A\n",
      " 95%|█████████▍| 159/168 [06:26<00:22,  2.47s/it]\u001b[A\n",
      " 95%|█████████▌| 160/168 [06:28<00:19,  2.46s/it]\u001b[A\n",
      " 96%|█████████▌| 161/168 [06:31<00:17,  2.45s/it]\u001b[A\n",
      " 96%|█████████▋| 162/168 [06:33<00:14,  2.44s/it]\u001b[A\n",
      " 97%|█████████▋| 163/168 [06:35<00:12,  2.45s/it]\u001b[A\n",
      " 98%|█████████▊| 164/168 [06:38<00:09,  2.45s/it]\u001b[A\n",
      " 98%|█████████▊| 165/168 [06:40<00:07,  2.45s/it]\u001b[A\n",
      " 99%|█████████▉| 166/168 [06:43<00:04,  2.44s/it]\u001b[A\n",
      " 99%|█████████▉| 167/168 [06:45<00:02,  2.44s/it]\u001b[A\n",
      "100%|██████████| 168/168 [06:48<00:00,  2.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1519, 10, 50, 50, 3)\n",
      "(168, 10, 50, 50, 3)\n",
      "(1519, 5)\n",
      "(168, 5)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "test_learn=[np.empty((data.get_labeldata().shape[0],10, 50, 50, 3), np.float)]*camera\n",
    "vali_learn=[np.empty((0,10, 50, 50, 3), np.float)]*camera\n",
    "test_label=data.get_labeldata()\n",
    "vali_label=np.empty((0,camera), np.float)\n",
    "\n",
    "print(test_label.shape)\n",
    "\n",
    "for j in range(0,camera):\n",
    "    test_learn[j]=data.get_learndata(j)\n",
    "\n",
    "for i in tqdm(range(0,int(0.1*test_label.shape[0]))):\n",
    "    random_angle = int(random.randint(0,test_label.shape[0]-1))\n",
    "    for j in range(0,camera):\n",
    "        vali_learn[j]=np.append(vali_learn[j], [test_learn[j][random_angle]],axis=0)\n",
    "        test_learn[j]=np.delete(test_learn[j], random_angle,0)\n",
    "    vali_label=np.append(vali_label, [test_label[random_angle]], axis=0)\n",
    "    test_label=np.delete(test_label, random_angle,0)\n",
    "\n",
    "print(test_learn[0].shape)\n",
    "print(vali_learn[0].shape)\n",
    "print(test_label.shape)\n",
    "print(vali_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
