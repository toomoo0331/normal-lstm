{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape, BatchNormalization, Add\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連x_test\n",
    "num_sample=100 #画像の総フレーム数\n",
    "timesteps=30 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "#画像関連\n",
    "channels=3\n",
    "img_width=100\n",
    "img_height=100\n",
    "\n",
    "# LSTMなどで用いる値\n",
    "n_hidden = 256    # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 5   # ミニバッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, camera_num, file_name, samples, timesteps, width, height):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=samples\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.learnData=[]\n",
    "        self.labelData=[]\n",
    "        \n",
    "        self.make_selection()\n",
    "        self.make_image()\n",
    "    \n",
    "    def make_selection(self):\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        one_hot = np.eye(self.camera_num)\n",
    "        for row2 in csv_selection:\n",
    "            self.labelData.append(one_hot[int(row2[1])])\n",
    "    \n",
    "    def make_image(self):\n",
    "        for i in range(0, self.camera_num):\n",
    "            img_list=[]\n",
    "            print()\n",
    "            for j in range(0,self.samples):\n",
    "                #どのくらいデータロードが進んでいるか\n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/self.samples)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / self.samples * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "                file_path = \"image/\"+str(i)+\"/\"+str(j)+\".jpg\"\n",
    "                img = Image.open(file_path).convert('RGB') ## Gray->L, RGB->RGB\n",
    "                img = img.resize((self.width, self.height))\n",
    "                x = np.array(img, dtype=np.float32)\n",
    "                x = x / 255.\n",
    "                \n",
    "                img_list.append(x)\n",
    "            self.learnData.append(img_list)\n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        test=[]\n",
    "        for i in range(0,self.samples-self.timesteps):\n",
    "            tmp_list=[]\n",
    "            for j in range(0, self.timesteps):\n",
    "                tmp_list.append(self.learnData[num][i+j])\n",
    "            test.append(tmp_list)\n",
    "        tmp=np.array(test)\n",
    "        tmp=tmp.astype(np.float)\n",
    "                \n",
    "        return tmp\n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        test=[]\n",
    "        for i in range(self.timesteps,self.samples):\n",
    "            test.append(self.labelData[i])\n",
    "        tmp = np.array(test)\n",
    "        tmp = tmp.astype(np.float)\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def show(self):\n",
    "        print()\n",
    "        #print(self.get_learndata(0).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/5 [=================== ] 99.000000%\n",
      "2/5 [=================== ] 99.000000%\n",
      "3/5 [=================== ] 99.000000%\n",
      "4/5 [=================== ] 99.000000%\n",
      "5/5 [=================== ] 99.000000%\n",
      "(70, 5)\n"
     ]
    }
   ],
   "source": [
    "data = Data(camera, \"./\", num_sample, timesteps, img_width, img_height)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18 :\n",
    "    def __init__(self, width, height, channels):\n",
    "        self.img_rows=height\n",
    "        self.img_cols=width\n",
    "        self.img_channels=channels\n",
    "    \n",
    "    def rescell(self, data, filters, kernel_size, option=False):\n",
    "        strides=(1,1)\n",
    "        if option:\n",
    "            strides=(2,2)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        data=Convolution2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Add()([x,data])\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def create_resnet18(self):\n",
    "        inputs=Input(shape=(self.img_rows, self.img_cols, self.img_channels))\n",
    "        x=Convolution2D(64,(7,7), padding=\"same\", input_shape=(self.img_rows, self.img_cols),activation=\"relu\")(inputs)\n",
    "        x=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,128,(3,3),True)\n",
    "        x=self.rescell(x,128,(3,3))\n",
    "\n",
    "        x=self.rescell(x,256,(3,3),True)\n",
    "        x=self.rescell(x,256,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,512,(3,3),True)\n",
    "        x=self.rescell(x,512,(3,3))\n",
    "        \n",
    "        model=Model(inputs=inputs,outputs=[x])\n",
    "        return model\n",
    "\n",
    "    def get_resnet18(self):\n",
    "        return self.create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_hidden, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.resnet = Resnet18(width, height, 3).get_resnet18()\n",
    "        self.sharedLayer = self.create_sharedmodel()\n",
    "    \n",
    "    def create_sharedmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        x = TimeDistributed(self.resnet,name=\"resnet\")(inputs)\n",
    "        x = TimeDistributed(GlobalAveragePooling2D(), name=\"GAP\")(x)\n",
    "        x = TimeDistributed(Dense(512), name=\"dense\")(x)\n",
    "        predictions = LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, 35),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(x)\n",
    "        \n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_layers\")\n",
    "        \n",
    "        return shared_layers\n",
    "    \n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input2 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input3 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input4 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input5 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        mid_feature1 = self.sharedLayer(model_input1)\n",
    "        mid_feature2 = self.sharedLayer(model_input2)\n",
    "        mid_feature3 = self.sharedLayer(model_input3)\n",
    "        mid_feature4 = self.sharedLayer(model_input4)\n",
    "        mid_feature5 = self.sharedLayer(model_input5)\n",
    "        \n",
    "        merged_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=-1)\n",
    "        \n",
    "        mid_dense = Dense(self.n_hidden, activation='sigmoid')(merged_vector)\n",
    "        predictions = Dense(self.n_out, activation='sigmoid')(mid_dense)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], outputs=predictions)\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train1, x_train2, x_train3, x_train4, x_train5, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train1, x_train2, x_train3, x_train4, x_train5], t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "              shuffle = True, callbacks = [early_stopping], validation_split = 0.3)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_102 (InputLayer)          (None, 30, 100, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_103 (InputLayer)          (None, 30, 100, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_104 (InputLayer)          (None, 30, 100, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_105 (InputLayer)          (None, 30, 100, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_106 (InputLayer)          (None, 30, 100, 100, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_layers (Model)           (None, 256)          12668992    input_102[0][0]                  \n",
      "                                                                 input_103[0][0]                  \n",
      "                                                                 input_104[0][0]                  \n",
      "                                                                 input_105[0][0]                  \n",
      "                                                                 input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 1280)         0           shared_layers[1][0]              \n",
      "                                                                 shared_layers[2][0]              \n",
      "                                                                 shared_layers[3][0]              \n",
      "                                                                 shared_layers[4][0]              \n",
      "                                                                 shared_layers[5][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 256)          327936      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 5)            1285        dense_48[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,998,213\n",
      "Trainable params: 12,990,277\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "# 学習\n",
    "model , hist = pred.train(data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4), \n",
    "                                data.get_labeldata(), batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)], \n",
    "                                data.get_labeldata(), batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "pre = [[0 for i in range(3)] for j in range(3)]\n",
    "# 正答率集計\n",
    "preds = model.predict([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)])\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    pred = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(data.get_labeldata()[i,:])\n",
    "    pre[pred][tar]+=1\n",
    "    if pred == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
