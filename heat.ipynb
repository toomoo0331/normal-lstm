{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps=20;\n",
    "number_of_samples=1016;\n",
    "nb_samples=number_of_samples;\n",
    "frame_row=180;\n",
    "frame_col=220;\n",
    "channels=3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def create_model(self):\n",
    "\n",
    "        model=Sequential()                          \n",
    "\n",
    "        model.add(TimeDistributed(Convolution2D(32, (3, 3),padding=\"same\"), input_shape=x_train.shape[1:]))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(Convolution2D(32, (3, 3))))\n",
    "        model.add(TimeDistributed(Activation('relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "        model.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(TimeDistributed(Dense(512)))\n",
    "\n",
    "        model.add(TimeDistributed(Dense(35, name=\"first_dense\" )))\n",
    "\n",
    "        model.add(LSTM(20, return_sequences=True, name=\"lstm_layer\"));\n",
    "\n",
    "        #%%\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(3, name=\"time_distr_dense_one\"))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        optimizer = Adam(lr=0.0005)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics = ['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def train(self, x_train1, x_train2, x_train3, x_train4, x_train5, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train1, x_train2, x_train3, x_train4, x_train5], t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "              shuffle = False, callbacks = [early_stopping], validation_split = 0.3)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n",
      "36\n",
      "76.0\n",
      "76\n",
      "137.0\n",
      "137\n",
      "176.0\n",
      "176\n",
      "271.0\n",
      "271\n",
      "308.0\n",
      "308\n",
      "398.0\n",
      "398\n",
      "502.0\n",
      "502\n",
      "606.0\n",
      "606\n",
      "719.0\n",
      "719\n",
      "770.0\n",
      "770\n",
      "818.0\n",
      "818\n",
      "867.0\n",
      "867\n",
      "890.0\n",
      "890\n",
      "959.0\n",
      "959\n",
      "1016.0\n",
      "1016\n",
      "==================================================\n",
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   ...\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]]\n",
      "adfsasd\n",
      "x_data.shape= (20320, 180, 220, 3)\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "t_data.shape= (1016, 3)\n"
     ]
    }
   ],
   "source": [
    "# 学習データ\n",
    "filename=\"G:/マイドライブ/lab/tennis/output/\"\n",
    "\n",
    "def makedata(num, learnData, labelData, key):\n",
    "    if(key == 0):readfolderName = filename + \"front\"+str(num)+\"/\"\n",
    "    elif(key==1):readfolderName = filename + \"front\"+str(num)+\"/player1/\"\n",
    "    elif(key==2):readfolderName = filename + \"front\"+str(num)+\"/player2/\"\n",
    "    for i in range(1,150):\n",
    "        try:\n",
    "            la=[]\n",
    "            df2 = csv.reader(open(readfolderName+\"csvdata1/label_\"+str(i)+\".csv\", 'r'))\n",
    "            for k in range(0,20):\n",
    "                imgPath = readfolderName+str(i)+\"/heat/save_\" + str(k) + \".jpg\"\n",
    "                im = Image.open(imgPath)\n",
    "                frameData = np.array(im)\n",
    "                frameData = np.reshape(frameData, (180, 220, 3))\n",
    "                learnData.append(frameData)\n",
    "            for row2 in df2:\n",
    "                labelData.append(row2)\n",
    "        except IOError:\n",
    "            pass\n",
    "            #rint ('\"%s\" cannot be opened.' % (str(num) + \",\"+str(key)+\" : \" + str(i)+\".csv\"))\n",
    "            # ラベルデータ\n",
    "            # クロス（左）／ストレート／クロス（右）\n",
    "\n",
    "    print(len(learnData)/20)\n",
    "    print(len(labelData))\n",
    "\n",
    "learnData=[]\n",
    "labelData=[]\n",
    "#makedata(3, learnData, labelData, 0)\n",
    "#makedata(5, learnData, labelData, 0)\n",
    "makedata(6, learnData, labelData, 1)\n",
    "makedata(6, learnData, labelData, 2)\n",
    "makedata(7, learnData, labelData, 1)\n",
    "makedata(7, learnData, labelData, 2)\n",
    "makedata(8, learnData, labelData, 1)\n",
    "makedata(8, learnData, labelData, 2)\n",
    "makedata(9, learnData, labelData, 1)\n",
    "makedata(9, learnData, labelData, 2)\n",
    "#makedata(10, learnData, labelData, 1)\n",
    "#makedata(10, learnData, labelData, 2)\n",
    "makedata(11, learnData, labelData, 1)\n",
    "makedata(11, learnData, labelData, 2)\n",
    "makedata(12, learnData, labelData, 1)\n",
    "makedata(12, learnData, labelData, 2)\n",
    "makedata(13, learnData, labelData, 1)\n",
    "makedata(13, learnData, labelData, 2)\n",
    "makedata(14, learnData, labelData, 1)\n",
    "makedata(14, learnData, labelData, 2)\n",
    "\n",
    "\n",
    "mat1 = np.array(learnData)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "print(\"==================================================\")\n",
    "mat2 = np.array(labelData)\n",
    "x_data = mat1.astype(np.float)\n",
    "#x_data = scaler.fit_transform(x_data)\n",
    "print(x_data)\n",
    "print(\"adfsasd\")\n",
    "print('x_data.shape=', x_data.shape)\n",
    "t_data = mat2.astype(np.float)                    \n",
    "print(t_data)\n",
    "print('t_data.shape=', t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nb_epoch=1;\n",
    "# batch_size=timesteps;\n",
    "\n",
    "# data= np.random.random((1016,timesteps,frame_row,frame_col,channels))\n",
    "# label=np.random.random((1016,timesteps,3))\n",
    "\n",
    "# x_train=data[0:900,:]\n",
    "# y_train=label[0:900]\n",
    "\n",
    "# x_test=data[900:,:]\n",
    "# y_test=label[900:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 5, 180, 220, 3) (1016, 3)\n",
      "(914, 5, 180, 220, 3) (102, 5, 180, 220, 3) (914, 3) (102, 3)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 5           # 入力系列数\n",
    "n_in = x_data.shape[1]   # 学習データ（＝入力）の列数\n",
    "n_out = t_data.shape[1]  # ラベルデータ（=出力）の列数\n",
    "len_seq = x_data.shape[0] - maxlen + 1\n",
    "data = []\n",
    "target = []\n",
    "for i in range(0, 1016):\n",
    "  data.append(x_data[15+ i*20:i*20+maxlen + 15, :])\n",
    "  target.append(t_data[i, :]) \n",
    "\n",
    "x = np.array(data).reshape(len(data), maxlen, 180,220,3)\n",
    "t = np.array(target).reshape(len(data), n_out)\n",
    "\n",
    "print(x.shape, t.shape)\n",
    "\n",
    "# ここからソースコードの後半\n",
    "n_train = int(len(data)*0.9)              # 訓練データ長\n",
    "x_train,x_test = np.vsplit(x, [n_train])  # 学習データを訓練用とテスト用に分割\n",
    "t_train,t_test = np.vsplit(t, [n_train])  # ラベルデータを訓練用とテスト用に分割\n",
    "\n",
    "print(x_train.shape, x_test.shape, t_train.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 5, 180, 220, 32)   896       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 5, 180, 220, 32)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 5, 178, 218, 32)   9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 5, 178, 218, 32)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 5, 89, 109, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 5, 89, 109, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 5, 310432)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 5, 512)            158941696 \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 5, 35)             17955     \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 5, 20)             4480      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "time_distr_dense_one (Dense) (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 158,974,578\n",
      "Trainable params: 158,974,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 639 samples, validate on 275 samples\n",
      "Epoch 1/100\n",
      "639/639 [==============================] - 31s 49ms/step - loss: 1.1887 - acc: 0.2973 - val_loss: 1.0787 - val_acc: 0.3818\n",
      "Epoch 2/100\n",
      "639/639 [==============================] - 25s 40ms/step - loss: 1.0759 - acc: 0.4366 - val_loss: 1.1005 - val_acc: 0.3564\n",
      "Epoch 3/100\n",
      "639/639 [==============================] - 25s 39ms/step - loss: 1.0682 - acc: 0.4413 - val_loss: 1.0994 - val_acc: 0.3564\n",
      "Epoch 4/100\n",
      "639/639 [==============================] - 25s 40ms/step - loss: 1.1059 - acc: 0.3725 - val_loss: 1.0852 - val_acc: 0.3709\n",
      "Epoch 5/100\n",
      "639/639 [==============================] - 25s 40ms/step - loss: 1.0839 - acc: 0.4366 - val_loss: 1.0868 - val_acc: 0.4036\n",
      "Epoch 6/100\n",
      "639/639 [==============================] - 25s 40ms/step - loss: 1.0750 - acc: 0.4163 - val_loss: 1.0960 - val_acc: 0.3564\n",
      "Epoch 00006: early stopping\n",
      "914/914 [==============================] - 12s 13ms/step\n",
      "score: [1.073015285529506, 0.41684902490359166]\n",
      "正答率: 0.4117647058823529\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 32    # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 5   # ミニバッチサイズ\n",
    "\n",
    "# モデル定義\n",
    "prediction = Prediction()\n",
    "# 学習\n",
    "model , hist = prediction.train(x_train, t_train, batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate(x_train, t_train, batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "pre = [[0 for i in range(3)] for j in range(3)]\n",
    "# 正答率集計\n",
    "preds = model.predict(x_test)\n",
    "correct = 0\n",
    "for i in range(len(preds)):\n",
    "    pred = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(t_test[i,:])\n",
    "    pre[pred][tar]+=1\n",
    "    if pred == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3d2cee5e8b1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtp0\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtp1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mpre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp0\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp0\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "tp0=pre[0][0]\n",
    "tp1=pre[1][1]\n",
    "tp2=pre[2][2]\n",
    "fp0=pre[0][1]+pre[0][2]\n",
    "fp1=pre[1][1]+pre[1][2]\n",
    "fp2=pre[2][1]+pre[2][2]\n",
    "fn0=pre[0][1]+pre[0][2]\n",
    "fn1=pre[1][1]+pre[1][2]\n",
    "fn2=pre[2][1]+pre[2][2]\n",
    "tn0=pre[1][1]+pre[1][2]+pre[2][1]+pre[2][2]\n",
    "tn1=pre[0][0]+pre[0][2]+pre[0][2]+pre[2][2]\n",
    "tn2=pre[0][0]+pre[0][1]*pre[1][0]+pre[1][1]\n",
    "\n",
    "acc = (tp0+tp1+tp2)/(pre[0][0]+pre[0][1]+pre[0][2]+pre[1][0]+pre[1][1]+pre[1][2]+pre[2][0]+pre[2][1]+pre[2][2])\n",
    "pre = (1/3)*((tp0/(tp0+fp0))+(tp1/(tp1+fp1))+(tp2/(tp2+fp2)))\n",
    "rec = (1/3)*((tp0/(tp0+fn0))+(tp1/(tp1+fn1))+(tp2/(tp2+fn2)))\n",
    "\n",
    "print(acc)\n",
    "print(pre)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
