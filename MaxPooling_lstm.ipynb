{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape, BatchNormalization, Add, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "from keras import backend as K\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping,TensorBoard\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連\n",
    "timesteps=10 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "rate = 10 #飛ばすフレーム数（30FPSを30/rateのFPSの動画に疑似変換する．）\n",
    "max_data = 7000 #AUG前の学習データの最大値\n",
    "\n",
    "#画像関連 \n",
    "channels=3\n",
    "img_width=50\n",
    "img_height=50\n",
    "\n",
    "#LSTMなどで用いる値\n",
    "epochs = 100 # エポック数 \n",
    "batch_size = 5 # バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, camera_num, file_name, timesteps, width, height,max_data):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=0\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.max_data=max_data\n",
    "        self.save_numpy()\n",
    "        \n",
    "    def save_numpy(self):\n",
    "        self.samples = int(self.get_sample()/rate)\n",
    "        if not (os.path.isfile(self.file_name+\"train/label_\"+str(rate)+\".npy\")):\n",
    "            self.make_numpy_learnData()\n",
    "            self.make_numpy_labelData()\n",
    "        self.learnData=np.load(self.file_name+\"train/learn_\"+str(rate)+\".npy\")\n",
    "        self.labelData=np.load(self.file_name+\"train/label_\"+str(rate)+\".npy\")\n",
    "    \n",
    "    def get_sample(self):\n",
    "        video_path = self.file_name+\"video/0.mp4\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        num = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        return num\n",
    "    \n",
    "    def make_numpy_labelData(self):\n",
    "        labelData=[[],[],[],[],[]]\n",
    "        test=[0,0,0,0,0]\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        for i,row2 in enumerate(csv_selection):\n",
    "            if(i%rate==0 and i > (self.timesteps-1)*rate-1 and i < self.max_data):\n",
    "                for j in range(self.camera_num):\n",
    "                    if j == int(row2[1]):\n",
    "                        labelData[j].append([1])\n",
    "                    else:\n",
    "                        labelData[j].append([0])\n",
    "                test[int(row2[1])]+=1\n",
    "        \n",
    "        \n",
    "        tmp_list = np.array(labelData)\n",
    "        tmp_list = tmp_list.astype(np.float)\n",
    "        np.save(self.file_name+\"train/label_\"+str(rate)+\".npy\", tmp_list)\n",
    "        print(tmp_list.shape)\n",
    "        print(test)\n",
    "    \n",
    "    \n",
    "    def make_numpy_learnData(self):\n",
    "        learnData=[]\n",
    "        for i in range(0, self.camera_num):\n",
    "            print()\n",
    "            img_list=[]\n",
    "            video_path = self.file_name+\"video/\"+str(i)+\".mp4\"\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            if (video_len>self.max_data):\n",
    "                video_len = self.max_data\n",
    "            for j in range(0,video_len):\n",
    "                \n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/video_len)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / video_len * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "                if(j%rate==0):\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    img=Image.fromarray(frame)\n",
    "                    img = img.resize((self.width, self.height))\n",
    "                    x = np.array(img, dtype=np.float32)\n",
    "                    x = x / 255.\n",
    "                    img_list.append(x)\n",
    "            learnData.append(img_list)\n",
    "            \n",
    "        tmp_list=np.array(learnData)\n",
    "        tmp_list=tmp_list.astype(np.float)\n",
    "        np.save(self.file_name+\"train/learn_\"+str(rate)+\".npy\", tmp_list)\n",
    "        print(tmp_list.shape)\n",
    "\n",
    "\n",
    "    def make_learndata(self):\n",
    "        data_name=self.file_name+\"train/learn_0_\"+str(rate)+\".npy\"\n",
    "        if (os.path.isfile(data_name)):\n",
    "            test=np.load(data_name)\n",
    "        else:\n",
    "            all_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "            tmp_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "            for i in range(0, self.labelData.shape[1]):\n",
    "                #まずはすべての分だけ回す\n",
    "                pro_size=20\n",
    "                bar = int(i*pro_size/self.labelData.shape[1])\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(i / self.labelData.shape[1] * 100.)\n",
    "                print('\\r [{0}] {1}%'.format(pro_bar, percent), end='')\n",
    "\n",
    "                for camera in range(0, self.camera_num):\n",
    "                    #カメラの台数だけ回す\n",
    "                    #tmp_list[camera]の同じ引数（番号）には同じ時間軸のsequenceが入っている．\n",
    "                    first_list =np.empty((0, self.width, self.height, 3), np.float)\n",
    "                    for l in range(0, self.timesteps):\n",
    "                        #timesteps分のndarrayを作る．\n",
    "                        img=self.learnData[camera,i+l]\n",
    "                        first_list =np.append(first_list, [img], axis=0)\n",
    "                    #あるカメラについて，１つのsequenceがfirst_listに出来上がっている状態．\n",
    "                    tmp_list[camera]=np.append(tmp_list[camera], [first_list], axis=0)\n",
    "\n",
    "\n",
    "                if(tmp_list[0].shape[0]>100 or i == self.labelData.shape[1]-1):\n",
    "                    #処理時間短縮のため，sequenceがtmp_listに溜まってきたら，全体に統合してまたtmp_listを初期化する．\n",
    "                    for camera in range(0, self.camera_num):\n",
    "                        all_list[camera]=np.append(all_list[camera], tmp_list[camera], axis=0)\n",
    "                        tmp_list[camera] = np.empty((0,self.timesteps, self.width, self.height, 3), np.float)\n",
    "            \n",
    "            for camera in range(0, self.camera_num):\n",
    "                print(all_list[camera].shape)\n",
    "                data_name=self.file_name+\"train/learn_\"+str(camera)+\"_\"+str(rate)\n",
    "                np.save(data_name, all_list[camera])\n",
    "    \n",
    "    \n",
    "    def make_labeldata(self):\n",
    "        data_name=self.file_name+\"train/final_label_\"+str(rate)+\"_.npy\"\n",
    "        if (os.path.isfile(data_name)):\n",
    "            test=np.load(data_name)\n",
    "        else:\n",
    "            print(self.labelData.shape)\n",
    "            np.save(data_name, self.labelData)\n",
    "    \n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        data_name=self.file_name+\"train/learn_\"+str(num)+\"_\"+str(rate)+\".npy\"\n",
    "        test=np.load(data_name)\n",
    "        return test\n",
    "    \n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        data_name=self.file_name+\"train/112final_label_\"+str(rate)+\"_.npy\"\n",
    "        test=np.load(data_name)\n",
    "        return test\n",
    "    \n",
    "    \n",
    "    def show(self):\n",
    "        print(0,self.get_learndata(0).shape)\n",
    "        print(1,self.get_learndata(1).shape)\n",
    "        print(2,self.get_learndata(2).shape)\n",
    "        print(3,self.get_learndata(3).shape)\n",
    "        print(4,self.get_learndata(4).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = DataLoader(camera, \"./data/20190427/\", timesteps, img_width, img_height,max_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 691, 1)\n",
      "0 (691, 10, 50, 50, 3)\n",
      "1 (691, 10, 50, 50, 3)\n",
      "2 (691, 10, 50, 50, 3)\n",
      "3 (691, 10, 50, 50, 3)\n",
      "4 (691, 10, 50, 50, 3)\n",
      "(5, 691, 1)\n"
     ]
    }
   ],
   "source": [
    "data.make_learndata()\n",
    "data.make_labeldata()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18 :\n",
    "    ##\n",
    "    ##　Resnet-18の作成\n",
    "    ##\n",
    "    def __init__(self, width, height, channels):\n",
    "        self.img_rows=height\n",
    "        self.img_cols=width\n",
    "        self.img_channels=channels\n",
    "    \n",
    "    def rescell(self, data, filters, kernel_size, option=False):\n",
    "        strides=(1,1)\n",
    "        if option:\n",
    "            strides=(2,2)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        data=Convolution2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Add()([x,data])\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def create_resnet18(self):\n",
    "        inputs=Input(shape=(self.img_rows, self.img_cols, self.img_channels))\n",
    "        x=Convolution2D(64,(7,7), padding=\"same\", input_shape=(self.img_rows, self.img_cols),activation=\"relu\")(inputs)\n",
    "        x=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,128,(3,3),True)\n",
    "        x=self.rescell(x,128,(3,3))\n",
    "\n",
    "        x=self.rescell(x,256,(3,3),True)\n",
    "        x=self.rescell(x,256,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,512,(3,3),True)\n",
    "        x=self.rescell(x,512,(3,3))\n",
    "        \n",
    "        model=Model(inputs=inputs,outputs=[x])\n",
    "        return model\n",
    "\n",
    "    def get_resnet18(self):\n",
    "        return self.create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.resnet = Resnet18(width, height, 3).get_resnet18()\n",
    "        self.sharedLSTMmodel = self.create_sharedLSTMmodel()\n",
    "        self.sharedRateModel = self.create_sharedRatemodel()\n",
    "    \n",
    "    \n",
    "    def create_sharedLSTMmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        x = TimeDistributed(self.resnet,name=\"resnet\")(inputs)\n",
    "        x = TimeDistributed(GlobalAveragePooling2D(), name=\"GAP\")(x)\n",
    "        x = TimeDistributed(Dense(512,activation='relu'), name=\"dense\")(x)\n",
    "        predictions = LSTM(256, batch_input_shape = (None, self.maxlen, 512),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(x)\n",
    "        \n",
    "        predictions =Reshape((1,256))(predictions)\n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_LSTMlayers\")\n",
    "        return shared_layers\n",
    "    \n",
    "    \n",
    "    def create_sharedRatemodel(self):\n",
    "        inputs = Input(shape=(512,))\n",
    "        mid_dense = Dense(256, activation='relu')(inputs)\n",
    "        predictions = Dense(1, activation='sigmoid')(mid_dense)\n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_Ratelayers\")\n",
    "        return shared_layers\n",
    "\n",
    "\n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input2 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input3 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input4 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input5 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        mid_feature1 = self.sharedLSTMmodel(model_input1)\n",
    "        mid_feature2 = self.sharedLSTMmodel(model_input2)\n",
    "        mid_feature3 = self.sharedLSTMmodel(model_input3)\n",
    "        mid_feature4 = self.sharedLSTMmodel(model_input4)\n",
    "        mid_feature5 = self.sharedLSTMmodel(model_input5)\n",
    "        \n",
    "        \n",
    "        pooling_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=1)\n",
    "        pooling_vector = MaxPooling1D(pool_size=camera)(pooling_vector)\n",
    "        \n",
    "        \n",
    "        merge_feature1 = keras.layers.concatenate([mid_feature1, pooling_vector], axis=-1)\n",
    "        merge_feature2 = keras.layers.concatenate([mid_feature2, pooling_vector], axis=-1)\n",
    "        merge_feature3 = keras.layers.concatenate([mid_feature3, pooling_vector], axis=-1)\n",
    "        merge_feature4 = keras.layers.concatenate([mid_feature4, pooling_vector], axis=-1)\n",
    "        merge_feature5 = keras.layers.concatenate([mid_feature5, pooling_vector], axis=-1)\n",
    "        \n",
    "        merge_feature1 = Reshape((512,))(merge_feature1)\n",
    "        merge_feature2 = Reshape((512,))(merge_feature2)\n",
    "        merge_feature3 = Reshape((512,))(merge_feature3)\n",
    "        merge_feature4 = Reshape((512,))(merge_feature4)\n",
    "        merge_feature5 = Reshape((512,))(merge_feature5)\n",
    "        \n",
    "        predictions1 = self.sharedRateModel(merge_feature1)\n",
    "        predictions2 = self.sharedRateModel(merge_feature2)\n",
    "        predictions3 = self.sharedRateModel(merge_feature3)\n",
    "        predictions4 = self.sharedRateModel(merge_feature4)\n",
    "        predictions5 = self.sharedRateModel(merge_feature5)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], \n",
    "                      outputs=[predictions1,predictions2,predictions3,predictions4,predictions5])\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def train(self, x_train, t_train, x_vali, t_vali, batch_size, epochs):\n",
    "        early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit(x=[x_train[0], x_train[1], x_train[2], x_train[3], x_train[4]], y=t_train, batch_size = batch_size,\n",
    "                         epochs = epochs, validation_data=([x_vali[0], x_vali[1], x_vali[2], x_vali[3], x_vali[4]], t_vali),\n",
    "                         callbacks = [early_stopping])\n",
    "        return model, hist\n",
    "    \n",
    "    \n",
    "    def train_keras(self, x_train, t_train, batch_size, epochs):\n",
    "        early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train[0], x_train[1], x_train[2], x_train[3], x_train[4]], \n",
    "                         [t_train[0], t_train[1], t_train[2], t_train[3], t_train[4]],\n",
    "                         batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "                         callbacks = [early_stopping], validation_split = 0.2)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 10, 50, 50, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_LSTMlayers (Model)       (None, 1, 256)       12668992    input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 5, 256)       0           shared_LSTMlayers[1][0]          \n",
      "                                                                 shared_LSTMlayers[2][0]          \n",
      "                                                                 shared_LSTMlayers[3][0]          \n",
      "                                                                 shared_LSTMlayers[4][0]          \n",
      "                                                                 shared_LSTMlayers[5][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 256)       0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 1, 512)       0           shared_LSTMlayers[1][0]          \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 1, 512)       0           shared_LSTMlayers[2][0]          \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 1, 512)       0           shared_LSTMlayers[3][0]          \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 1, 512)       0           shared_LSTMlayers[4][0]          \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 1, 512)       0           shared_LSTMlayers[5][0]          \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 512)          0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 512)          0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 512)          0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 512)          0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 512)          0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "shared_Ratelayers (Model)       (None, 1)            131585      reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "                                                                 reshape_15[0][0]                 \n",
      "                                                                 reshape_16[0][0]                 \n",
      "                                                                 reshape_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 12,800,577\n",
      "Trainable params: 12,792,641\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "pred = Prediction(timesteps, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 691, 1)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "test_learn=[np.empty((data.get_labeldata().shape[0],10, 50, 50, 3), np.float)]*camera\n",
    "vali_learn=[np.empty((0,10, 50, 50, 3), np.float)]*camera\n",
    "test_label=data.get_labeldata()\n",
    "vali_label=np.empty((0,camera), np.float)\n",
    "\n",
    "print(test_label.shape)\n",
    "\n",
    "for j in range(0,camera):\n",
    "    test_learn[j]=data.get_learndata(j)\n",
    "\n",
    "# for i in tqdm(range(0,int(0.1*test_label.shape[0]))):\n",
    "#     random_angle = int(random.randint(0,test_label.shape[0]-1))\n",
    "#     for j in range(0,camera):\n",
    "#         vali_learn[j]=np.append(vali_learn[j], [test_learn[j][random_angle]],axis=0)\n",
    "#         test_learn[j]=np.delete(test_learn[j], random_angle,0)\n",
    "#     vali_label=np.append(vali_label, [test_label[random_angle]], axis=0)\n",
    "#     test_label=np.delete(test_label, random_angle,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kei666/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kei666/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 552 samples, validate on 139 samples\n",
      "Epoch 1/100\n",
      "552/552 [==============================] - 69s 125ms/step - loss: 2.5898 - shared_Ratelayers_loss: 0.9694 - shared_Ratelayers_acc: 0.7536 - shared_Ratelayers_acc_1: 0.9601 - shared_Ratelayers_acc_2: 0.9167 - shared_Ratelayers_acc_3: 0.8261 - shared_Ratelayers_acc_4: 0.4837 - val_loss: 2.5301 - val_shared_Ratelayers_loss: 1.0612 - val_shared_Ratelayers_acc: 0.8058 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.3094\n",
      "Epoch 2/100\n",
      "552/552 [==============================] - 33s 60ms/step - loss: 2.4103 - shared_Ratelayers_loss: 0.8803 - shared_Ratelayers_acc: 0.7681 - shared_Ratelayers_acc_1: 0.9692 - shared_Ratelayers_acc_2: 0.9275 - shared_Ratelayers_acc_3: 0.8424 - shared_Ratelayers_acc_4: 0.4873 - val_loss: 2.7548 - val_shared_Ratelayers_loss: 1.0376 - val_shared_Ratelayers_acc: 0.8058 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.3094\n",
      "Epoch 3/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 2.2603 - shared_Ratelayers_loss: 0.8585 - shared_Ratelayers_acc: 0.7935 - shared_Ratelayers_acc_1: 0.9692 - shared_Ratelayers_acc_2: 0.9293 - shared_Ratelayers_acc_3: 0.8442 - shared_Ratelayers_acc_4: 0.5344 - val_loss: 2.3183 - val_shared_Ratelayers_loss: 1.1344 - val_shared_Ratelayers_acc: 0.6619 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.2950\n",
      "Epoch 4/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 1.8285 - shared_Ratelayers_loss: 0.6365 - shared_Ratelayers_acc: 0.8261 - shared_Ratelayers_acc_1: 0.9728 - shared_Ratelayers_acc_2: 0.9221 - shared_Ratelayers_acc_3: 0.8333 - shared_Ratelayers_acc_4: 0.6793 - val_loss: 2.5951 - val_shared_Ratelayers_loss: 1.5316 - val_shared_Ratelayers_acc: 0.8058 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.3094\n",
      "Epoch 5/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 1.7092 - shared_Ratelayers_loss: 0.6019 - shared_Ratelayers_acc: 0.8514 - shared_Ratelayers_acc_1: 0.9801 - shared_Ratelayers_acc_2: 0.9330 - shared_Ratelayers_acc_3: 0.8370 - shared_Ratelayers_acc_4: 0.6685 - val_loss: 2.6614 - val_shared_Ratelayers_loss: 1.1386 - val_shared_Ratelayers_acc: 0.6043 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.7914 - val_shared_Ratelayers_acc_4: 0.3309\n",
      "Epoch 6/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 1.5743 - shared_Ratelayers_loss: 0.5817 - shared_Ratelayers_acc: 0.8659 - shared_Ratelayers_acc_1: 0.9764 - shared_Ratelayers_acc_2: 0.9312 - shared_Ratelayers_acc_3: 0.8315 - shared_Ratelayers_acc_4: 0.6993 - val_loss: 2.7955 - val_shared_Ratelayers_loss: 0.7866 - val_shared_Ratelayers_acc: 0.6259 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9353 - val_shared_Ratelayers_acc_3: 0.8273 - val_shared_Ratelayers_acc_4: 0.3885\n",
      "Epoch 7/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 1.5197 - shared_Ratelayers_loss: 0.5447 - shared_Ratelayers_acc: 0.8678 - shared_Ratelayers_acc_1: 0.9783 - shared_Ratelayers_acc_2: 0.9257 - shared_Ratelayers_acc_3: 0.8279 - shared_Ratelayers_acc_4: 0.7011 - val_loss: 2.6918 - val_shared_Ratelayers_loss: 1.5372 - val_shared_Ratelayers_acc: 0.6835 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8561 - val_shared_Ratelayers_acc_4: 0.3165\n",
      "Epoch 8/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 1.4525 - shared_Ratelayers_loss: 0.5242 - shared_Ratelayers_acc: 0.8822 - shared_Ratelayers_acc_1: 0.9801 - shared_Ratelayers_acc_2: 0.9275 - shared_Ratelayers_acc_3: 0.8315 - shared_Ratelayers_acc_4: 0.7264 - val_loss: 2.8315 - val_shared_Ratelayers_loss: 0.9874 - val_shared_Ratelayers_acc: 0.6403 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9928 - val_shared_Ratelayers_acc_3: 0.7482 - val_shared_Ratelayers_acc_4: 0.3741\n",
      "Epoch 9/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 1.3932 - shared_Ratelayers_loss: 0.5030 - shared_Ratelayers_acc: 0.8786 - shared_Ratelayers_acc_1: 0.9801 - shared_Ratelayers_acc_2: 0.9149 - shared_Ratelayers_acc_3: 0.8170 - shared_Ratelayers_acc_4: 0.7301 - val_loss: 3.2802 - val_shared_Ratelayers_loss: 1.4756 - val_shared_Ratelayers_acc: 0.6115 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.7914 - val_shared_Ratelayers_acc_4: 0.3741\n",
      "Epoch 10/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 1.3591 - shared_Ratelayers_loss: 0.5103 - shared_Ratelayers_acc: 0.8895 - shared_Ratelayers_acc_1: 0.9801 - shared_Ratelayers_acc_2: 0.9221 - shared_Ratelayers_acc_3: 0.8225 - shared_Ratelayers_acc_4: 0.7446 - val_loss: 3.3489 - val_shared_Ratelayers_loss: 1.1199 - val_shared_Ratelayers_acc: 0.3885 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.8849 - val_shared_Ratelayers_acc_3: 0.5468 - val_shared_Ratelayers_acc_4: 0.4460\n",
      "Epoch 11/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 1.2743 - shared_Ratelayers_loss: 0.4749 - shared_Ratelayers_acc: 0.8696 - shared_Ratelayers_acc_1: 0.9837 - shared_Ratelayers_acc_2: 0.9221 - shared_Ratelayers_acc_3: 0.8460 - shared_Ratelayers_acc_4: 0.7409 - val_loss: 2.2356 - val_shared_Ratelayers_loss: 0.7906 - val_shared_Ratelayers_acc: 0.6115 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8058 - val_shared_Ratelayers_acc_4: 0.5324\n",
      "Epoch 12/100\n",
      "552/552 [==============================] - 33s 60ms/step - loss: 1.2372 - shared_Ratelayers_loss: 0.4717 - shared_Ratelayers_acc: 0.8859 - shared_Ratelayers_acc_1: 0.9837 - shared_Ratelayers_acc_2: 0.9348 - shared_Ratelayers_acc_3: 0.8388 - shared_Ratelayers_acc_4: 0.7446 - val_loss: 2.4778 - val_shared_Ratelayers_loss: 0.8381 - val_shared_Ratelayers_acc: 0.6763 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8633 - val_shared_Ratelayers_acc_4: 0.3165\n",
      "Epoch 13/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 1.1781 - shared_Ratelayers_loss: 0.4507 - shared_Ratelayers_acc: 0.8822 - shared_Ratelayers_acc_1: 0.9891 - shared_Ratelayers_acc_2: 0.9475 - shared_Ratelayers_acc_3: 0.8388 - shared_Ratelayers_acc_4: 0.7663 - val_loss: 2.0832 - val_shared_Ratelayers_loss: 1.0860 - val_shared_Ratelayers_acc: 0.6619 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.4892\n",
      "Epoch 14/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 1.1982 - shared_Ratelayers_loss: 0.4410 - shared_Ratelayers_acc: 0.8822 - shared_Ratelayers_acc_1: 0.9855 - shared_Ratelayers_acc_2: 0.9348 - shared_Ratelayers_acc_3: 0.8351 - shared_Ratelayers_acc_4: 0.7736 - val_loss: 2.9438 - val_shared_Ratelayers_loss: 1.1618 - val_shared_Ratelayers_acc: 0.6043 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9928 - val_shared_Ratelayers_acc_3: 0.6835 - val_shared_Ratelayers_acc_4: 0.4532\n",
      "Epoch 15/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 1.1978 - shared_Ratelayers_loss: 0.4140 - shared_Ratelayers_acc: 0.8949 - shared_Ratelayers_acc_1: 0.9837 - shared_Ratelayers_acc_2: 0.9366 - shared_Ratelayers_acc_3: 0.8442 - shared_Ratelayers_acc_4: 0.7772 - val_loss: 3.4237 - val_shared_Ratelayers_loss: 0.9778 - val_shared_Ratelayers_acc: 0.5827 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9928 - val_shared_Ratelayers_acc_3: 0.6331 - val_shared_Ratelayers_acc_4: 0.5683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 1.1339 - shared_Ratelayers_loss: 0.4125 - shared_Ratelayers_acc: 0.9004 - shared_Ratelayers_acc_1: 0.9873 - shared_Ratelayers_acc_2: 0.9366 - shared_Ratelayers_acc_3: 0.8351 - shared_Ratelayers_acc_4: 0.8043 - val_loss: 2.0767 - val_shared_Ratelayers_loss: 1.0101 - val_shared_Ratelayers_acc: 0.7986 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.3381\n",
      "Epoch 17/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 1.1272 - shared_Ratelayers_loss: 0.4188 - shared_Ratelayers_acc: 0.9094 - shared_Ratelayers_acc_1: 0.9891 - shared_Ratelayers_acc_2: 0.9493 - shared_Ratelayers_acc_3: 0.8514 - shared_Ratelayers_acc_4: 0.7917 - val_loss: 2.0526 - val_shared_Ratelayers_loss: 0.7763 - val_shared_Ratelayers_acc: 0.6835 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9496 - val_shared_Ratelayers_acc_3: 0.8705 - val_shared_Ratelayers_acc_4: 0.5971\n",
      "Epoch 18/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 1.0506 - shared_Ratelayers_loss: 0.3903 - shared_Ratelayers_acc: 0.9167 - shared_Ratelayers_acc_1: 0.9946 - shared_Ratelayers_acc_2: 0.9384 - shared_Ratelayers_acc_3: 0.8442 - shared_Ratelayers_acc_4: 0.7971 - val_loss: 2.5610 - val_shared_Ratelayers_loss: 1.0358 - val_shared_Ratelayers_acc: 0.6906 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.5683\n",
      "Epoch 19/100\n",
      "552/552 [==============================] - 33s 59ms/step - loss: 1.0378 - shared_Ratelayers_loss: 0.3731 - shared_Ratelayers_acc: 0.9239 - shared_Ratelayers_acc_1: 0.9891 - shared_Ratelayers_acc_2: 0.9475 - shared_Ratelayers_acc_3: 0.8478 - shared_Ratelayers_acc_4: 0.8207 - val_loss: 2.6680 - val_shared_Ratelayers_loss: 0.9992 - val_shared_Ratelayers_acc: 0.6259 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9856 - val_shared_Ratelayers_acc_3: 0.8129 - val_shared_Ratelayers_acc_4: 0.5396\n",
      "Epoch 20/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 0.9687 - shared_Ratelayers_loss: 0.3769 - shared_Ratelayers_acc: 0.9167 - shared_Ratelayers_acc_1: 0.9928 - shared_Ratelayers_acc_2: 0.9420 - shared_Ratelayers_acc_3: 0.8641 - shared_Ratelayers_acc_4: 0.8261 - val_loss: 1.7846 - val_shared_Ratelayers_loss: 0.6435 - val_shared_Ratelayers_acc: 0.7122 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.7266 - val_shared_Ratelayers_acc_4: 0.6619\n",
      "Epoch 21/100\n",
      "552/552 [==============================] - 33s 59ms/step - loss: 0.9491 - shared_Ratelayers_loss: 0.3558 - shared_Ratelayers_acc: 0.9112 - shared_Ratelayers_acc_1: 0.9928 - shared_Ratelayers_acc_2: 0.9438 - shared_Ratelayers_acc_3: 0.8496 - shared_Ratelayers_acc_4: 0.8152 - val_loss: 2.4118 - val_shared_Ratelayers_loss: 1.0345 - val_shared_Ratelayers_acc: 0.7410 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.7554 - val_shared_Ratelayers_acc_4: 0.5180\n",
      "Epoch 22/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 0.9800 - shared_Ratelayers_loss: 0.3881 - shared_Ratelayers_acc: 0.9185 - shared_Ratelayers_acc_1: 0.9909 - shared_Ratelayers_acc_2: 0.9511 - shared_Ratelayers_acc_3: 0.8623 - shared_Ratelayers_acc_4: 0.8043 - val_loss: 2.6724 - val_shared_Ratelayers_loss: 1.5075 - val_shared_Ratelayers_acc: 0.8058 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8921 - val_shared_Ratelayers_acc_4: 0.3094\n",
      "Epoch 23/100\n",
      "552/552 [==============================] - 33s 59ms/step - loss: 0.9201 - shared_Ratelayers_loss: 0.3353 - shared_Ratelayers_acc: 0.9130 - shared_Ratelayers_acc_1: 0.9946 - shared_Ratelayers_acc_2: 0.9457 - shared_Ratelayers_acc_3: 0.8696 - shared_Ratelayers_acc_4: 0.8388 - val_loss: 2.8468 - val_shared_Ratelayers_loss: 1.5504 - val_shared_Ratelayers_acc: 0.6906 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.7122 - val_shared_Ratelayers_acc_4: 0.3885\n",
      "Epoch 24/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.8582 - shared_Ratelayers_loss: 0.3419 - shared_Ratelayers_acc: 0.9312 - shared_Ratelayers_acc_1: 0.9964 - shared_Ratelayers_acc_2: 0.9565 - shared_Ratelayers_acc_3: 0.8732 - shared_Ratelayers_acc_4: 0.8370 - val_loss: 2.4505 - val_shared_Ratelayers_loss: 0.8405 - val_shared_Ratelayers_acc: 0.6619 - val_shared_Ratelayers_acc_1: 0.9856 - val_shared_Ratelayers_acc_2: 0.9712 - val_shared_Ratelayers_acc_3: 0.6835 - val_shared_Ratelayers_acc_4: 0.6619\n",
      "Epoch 25/100\n",
      "552/552 [==============================] - 33s 59ms/step - loss: 0.9362 - shared_Ratelayers_loss: 0.3502 - shared_Ratelayers_acc: 0.9130 - shared_Ratelayers_acc_1: 0.9964 - shared_Ratelayers_acc_2: 0.9457 - shared_Ratelayers_acc_3: 0.8804 - shared_Ratelayers_acc_4: 0.8297 - val_loss: 2.4239 - val_shared_Ratelayers_loss: 0.6479 - val_shared_Ratelayers_acc: 0.5827 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9784 - val_shared_Ratelayers_acc_3: 0.6403 - val_shared_Ratelayers_acc_4: 0.6547\n",
      "Epoch 26/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.8113 - shared_Ratelayers_loss: 0.3165 - shared_Ratelayers_acc: 0.9348 - shared_Ratelayers_acc_1: 0.9964 - shared_Ratelayers_acc_2: 0.9511 - shared_Ratelayers_acc_3: 0.8659 - shared_Ratelayers_acc_4: 0.8442 - val_loss: 2.3866 - val_shared_Ratelayers_loss: 0.6202 - val_shared_Ratelayers_acc: 0.5036 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.8489 - val_shared_Ratelayers_acc_3: 0.5036 - val_shared_Ratelayers_acc_4: 0.6906\n",
      "Epoch 27/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.9006 - shared_Ratelayers_loss: 0.3177 - shared_Ratelayers_acc: 0.9130 - shared_Ratelayers_acc_1: 0.9891 - shared_Ratelayers_acc_2: 0.9656 - shared_Ratelayers_acc_3: 0.8732 - shared_Ratelayers_acc_4: 0.8478 - val_loss: 2.5803 - val_shared_Ratelayers_loss: 0.9444 - val_shared_Ratelayers_acc: 0.6331 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9856 - val_shared_Ratelayers_acc_3: 0.8273 - val_shared_Ratelayers_acc_4: 0.5683\n",
      "Epoch 28/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.8411 - shared_Ratelayers_loss: 0.3473 - shared_Ratelayers_acc: 0.9420 - shared_Ratelayers_acc_1: 0.9928 - shared_Ratelayers_acc_2: 0.9583 - shared_Ratelayers_acc_3: 0.8786 - shared_Ratelayers_acc_4: 0.8225 - val_loss: 2.5858 - val_shared_Ratelayers_loss: 1.3448 - val_shared_Ratelayers_acc: 0.6619 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.8058 - val_shared_Ratelayers_acc_4: 0.4676\n",
      "Epoch 29/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.7973 - shared_Ratelayers_loss: 0.3187 - shared_Ratelayers_acc: 0.9402 - shared_Ratelayers_acc_1: 0.9946 - shared_Ratelayers_acc_2: 0.9475 - shared_Ratelayers_acc_3: 0.8859 - shared_Ratelayers_acc_4: 0.8424 - val_loss: 2.4540 - val_shared_Ratelayers_loss: 0.7123 - val_shared_Ratelayers_acc: 0.5755 - val_shared_Ratelayers_acc_1: 0.9784 - val_shared_Ratelayers_acc_2: 0.8849 - val_shared_Ratelayers_acc_3: 0.6978 - val_shared_Ratelayers_acc_4: 0.6331\n",
      "Epoch 30/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.7536 - shared_Ratelayers_loss: 0.2779 - shared_Ratelayers_acc: 0.9384 - shared_Ratelayers_acc_1: 1.0000 - shared_Ratelayers_acc_2: 0.9547 - shared_Ratelayers_acc_3: 0.8841 - shared_Ratelayers_acc_4: 0.8641 - val_loss: 2.5448 - val_shared_Ratelayers_loss: 1.1833 - val_shared_Ratelayers_acc: 0.6547 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.7050 - val_shared_Ratelayers_acc_4: 0.5396\n",
      "Epoch 31/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.7503 - shared_Ratelayers_loss: 0.2966 - shared_Ratelayers_acc: 0.9438 - shared_Ratelayers_acc_1: 0.9928 - shared_Ratelayers_acc_2: 0.9511 - shared_Ratelayers_acc_3: 0.8750 - shared_Ratelayers_acc_4: 0.8514 - val_loss: 2.9237 - val_shared_Ratelayers_loss: 1.4506 - val_shared_Ratelayers_acc: 0.7122 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 1.0000 - val_shared_Ratelayers_acc_3: 0.6547 - val_shared_Ratelayers_acc_4: 0.4964\n",
      "Epoch 32/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 0.7581 - shared_Ratelayers_loss: 0.2982 - shared_Ratelayers_acc: 0.9547 - shared_Ratelayers_acc_1: 1.0000 - shared_Ratelayers_acc_2: 0.9457 - shared_Ratelayers_acc_3: 0.8786 - shared_Ratelayers_acc_4: 0.8587 - val_loss: 2.9083 - val_shared_Ratelayers_loss: 1.4321 - val_shared_Ratelayers_acc: 0.7482 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9784 - val_shared_Ratelayers_acc_3: 0.8129 - val_shared_Ratelayers_acc_4: 0.4460\n",
      "Epoch 33/100\n",
      "552/552 [==============================] - 33s 59ms/step - loss: 0.7459 - shared_Ratelayers_loss: 0.3255 - shared_Ratelayers_acc: 0.9529 - shared_Ratelayers_acc_1: 0.9982 - shared_Ratelayers_acc_2: 0.9728 - shared_Ratelayers_acc_3: 0.8732 - shared_Ratelayers_acc_4: 0.8406 - val_loss: 4.2829 - val_shared_Ratelayers_loss: 2.2243 - val_shared_Ratelayers_acc: 0.8273 - val_shared_Ratelayers_acc_1: 0.9640 - val_shared_Ratelayers_acc_2: 0.9640 - val_shared_Ratelayers_acc_3: 0.8129 - val_shared_Ratelayers_acc_4: 0.4748\n",
      "Epoch 34/100\n",
      "552/552 [==============================] - 33s 59ms/step - loss: 0.6922 - shared_Ratelayers_loss: 0.2641 - shared_Ratelayers_acc: 0.9529 - shared_Ratelayers_acc_1: 0.9982 - shared_Ratelayers_acc_2: 0.9692 - shared_Ratelayers_acc_3: 0.9094 - shared_Ratelayers_acc_4: 0.8659 - val_loss: 2.2380 - val_shared_Ratelayers_loss: 0.6946 - val_shared_Ratelayers_acc: 0.5827 - val_shared_Ratelayers_acc_1: 0.9856 - val_shared_Ratelayers_acc_2: 0.9137 - val_shared_Ratelayers_acc_3: 0.6331 - val_shared_Ratelayers_acc_4: 0.5827\n",
      "Epoch 35/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 0.7597 - shared_Ratelayers_loss: 0.2898 - shared_Ratelayers_acc: 0.9384 - shared_Ratelayers_acc_1: 0.9946 - shared_Ratelayers_acc_2: 0.9620 - shared_Ratelayers_acc_3: 0.8841 - shared_Ratelayers_acc_4: 0.8442 - val_loss: 2.5560 - val_shared_Ratelayers_loss: 1.0644 - val_shared_Ratelayers_acc: 0.6906 - val_shared_Ratelayers_acc_1: 0.9928 - val_shared_Ratelayers_acc_2: 0.9784 - val_shared_Ratelayers_acc_3: 0.7266 - val_shared_Ratelayers_acc_4: 0.3597\n",
      "Epoch 36/100\n",
      "552/552 [==============================] - 32s 57ms/step - loss: 0.7375 - shared_Ratelayers_loss: 0.2746 - shared_Ratelayers_acc: 0.9402 - shared_Ratelayers_acc_1: 0.9964 - shared_Ratelayers_acc_2: 0.9529 - shared_Ratelayers_acc_3: 0.8859 - shared_Ratelayers_acc_4: 0.8569 - val_loss: 3.5266 - val_shared_Ratelayers_loss: 1.2211 - val_shared_Ratelayers_acc: 0.6043 - val_shared_Ratelayers_acc_1: 0.9856 - val_shared_Ratelayers_acc_2: 0.9928 - val_shared_Ratelayers_acc_3: 0.6763 - val_shared_Ratelayers_acc_4: 0.6331\n",
      "Epoch 37/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.7923 - shared_Ratelayers_loss: 0.3035 - shared_Ratelayers_acc: 0.9529 - shared_Ratelayers_acc_1: 0.9946 - shared_Ratelayers_acc_2: 0.9493 - shared_Ratelayers_acc_3: 0.8750 - shared_Ratelayers_acc_4: 0.8388 - val_loss: 2.2018 - val_shared_Ratelayers_loss: 0.7087 - val_shared_Ratelayers_acc: 0.6978 - val_shared_Ratelayers_acc_1: 0.9712 - val_shared_Ratelayers_acc_2: 0.9353 - val_shared_Ratelayers_acc_3: 0.7050 - val_shared_Ratelayers_acc_4: 0.6906\n",
      "Epoch 38/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 0.7356 - shared_Ratelayers_loss: 0.2933 - shared_Ratelayers_acc: 0.9529 - shared_Ratelayers_acc_1: 0.9928 - shared_Ratelayers_acc_2: 0.9638 - shared_Ratelayers_acc_3: 0.9004 - shared_Ratelayers_acc_4: 0.8460 - val_loss: 2.3264 - val_shared_Ratelayers_loss: 0.8249 - val_shared_Ratelayers_acc: 0.6619 - val_shared_Ratelayers_acc_1: 0.9856 - val_shared_Ratelayers_acc_2: 0.9137 - val_shared_Ratelayers_acc_3: 0.7266 - val_shared_Ratelayers_acc_4: 0.6403\n",
      "Epoch 39/100\n",
      "552/552 [==============================] - 32s 59ms/step - loss: 0.7905 - shared_Ratelayers_loss: 0.2811 - shared_Ratelayers_acc: 0.9330 - shared_Ratelayers_acc_1: 0.9891 - shared_Ratelayers_acc_2: 0.9511 - shared_Ratelayers_acc_3: 0.8913 - shared_Ratelayers_acc_4: 0.8478 - val_loss: 1.8819 - val_shared_Ratelayers_loss: 0.7466 - val_shared_Ratelayers_acc: 0.7410 - val_shared_Ratelayers_acc_1: 0.9784 - val_shared_Ratelayers_acc_2: 0.9856 - val_shared_Ratelayers_acc_3: 0.6835 - val_shared_Ratelayers_acc_4: 0.6043\n",
      "Epoch 40/100\n",
      "552/552 [==============================] - 32s 58ms/step - loss: 0.7197 - shared_Ratelayers_loss: 0.2921 - shared_Ratelayers_acc: 0.9384 - shared_Ratelayers_acc_1: 0.9964 - shared_Ratelayers_acc_2: 0.9547 - shared_Ratelayers_acc_3: 0.8949 - shared_Ratelayers_acc_4: 0.8514 - val_loss: 2.4494 - val_shared_Ratelayers_loss: 1.1096 - val_shared_Ratelayers_acc: 0.6691 - val_shared_Ratelayers_acc_1: 0.9784 - val_shared_Ratelayers_acc_2: 0.9928 - val_shared_Ratelayers_acc_3: 0.7410 - val_shared_Ratelayers_acc_4: 0.4964\n",
      "Epoch 00040: early stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 5 array(s), but instead got the following list of 1 arrays: [array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [1.]],\n\n ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-cf3a06055392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_learn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# テスト\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_learn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lstm/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 5 array(s), but instead got the following list of 1 arrays: [array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [1.]],\n\n ..."
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "#model , hist = pred.train(test_learn, test_label, vali_learn, vali_label, batch_size, epochs)\n",
    "model , hist = pred.train_keras(test_learn, test_label, batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate(test_learn, test_label, batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model):\n",
    "    for i in model.layers:\n",
    "        i.trainable = False\n",
    "        if isinstance(i, Model):\n",
    "            freeze_layers(i)\n",
    "    return model\n",
    "\n",
    "model_freezed = freeze_layers(model)\n",
    "model_freezed.save('file0205.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_loss(hist):\n",
    "    # 損失値(Loss)の遷移のプロット\n",
    "    plt.plot(hist.history['loss'],label=\"loss for training\")\n",
    "    plt.plot(hist.history['val_loss'],label=\"loss for validation\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_history_acc(hist):\n",
    "    # 精度(Accuracy)の遷移のプロット\n",
    "    plt.plot(hist.history['acc'],label=\"loss for training\")\n",
    "    plt.plot(hist.history['val_acc'],label=\"loss for validation\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()\n",
    "\n",
    "plot_history_loss(hist)\n",
    "plot_history_acc(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カメラ番号をランダムに並び替えることでデータの偏りをなくそうというデータ作成プログラム\n",
    "\n",
    "\n",
    "# def make_learndata(self):\n",
    "#         data_name=self.file_name+\"learn_0_\"+str(rate)+\".npy\"\n",
    "#         if (os.path.isfile(data_name)):\n",
    "#             test=np.load(data_name)\n",
    "#         else:\n",
    "#             all_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "#             tmp_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "#             for i in range(0, self.labelData.shape[0]):\n",
    "#                 #まずはすべての分だけ回す\n",
    "#                 pro_size=20\n",
    "#                 bar = int(i*pro_size/self.labelData.shape[0])\n",
    "#                 pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "#                 percent ='{:03f}'.format(i / self.labelData.shape[0] * 100.)\n",
    "#                 print('\\r [{0}] {1}%'.format(pro_bar, percent), end='')\n",
    "                            \n",
    "#                 for j in range(0,self.camera_num):\n",
    "#                     for camera in range(0, self.camera_num):\n",
    "#                         #カメラの台数だけ回す\n",
    "#                         #tmp_list[camera]の同じ引数（番号）には角度を同じ分だけずらした同じ時間軸のsequenceが入っている．\n",
    "#                         first_list =np.empty((0, self.width, self.height, 3), np.float)\n",
    "#                         for l in range(0, self.timesteps):\n",
    "#                             #timesteps分のndarrayを作る．\n",
    "#                             img=self.learnData[camera,i+l]\n",
    "#                             first_list =np.append(first_list, [img], axis=0)\n",
    "#                         #あるカメラについて，１つのsequenceがfirst_listに出来上がっている状態．\n",
    "#                         tmp_camera_num=self.camera_return(camera+j)\n",
    "#                         tmp_list[tmp_camera_num]=np.append(tmp_list[tmp_camera_num], [first_list], axis=0)\n",
    "    \n",
    "\n",
    "#                 if(tmp_list[0].shape[0]>100 or i == self.labelData.shape[0]-1):\n",
    "#                     #処理時間短縮のため，sequenceがtmp_listに溜まってきたら，全体に統合してまたtmp_listを初期化する．\n",
    "#                     for camera in range(0, self.camera_num):\n",
    "#                         all_list[camera]=np.append(all_list[camera], tmp_list[camera], axis=0)\n",
    "#                         tmp_list[camera] = np.empty((0,self.timesteps, self.width, self.height, 3), np.float)\n",
    "            \n",
    "#             for camera in range(0, self.camera_num):\n",
    "#                 print(all_list[camera].shape)\n",
    "#                 data_name=self.file_name+\"learn_\"+str(camera)+\"_\"+str(rate)\n",
    "#                 np.save(data_name, all_list[camera])\n",
    "    \n",
    "    \n",
    "#     def make_labeldata(self):\n",
    "#         data_name=self.file_name+\"final_label_\"+str(rate)+\"_.npy\"\n",
    "#         if (os.path.isfile(data_name)):\n",
    "#             test=np.load(data_name)\n",
    "#         else:\n",
    "#             test = np.empty((0,self.camera_num), np.float)\n",
    "#             for i in range(0,self.labelData.shape[0]):\n",
    "#                 for j in range(0, self.camera_num):\n",
    "#                     tmp=self.camera_return(np.argmax(self.labelData[i])+j)\n",
    "#                     a_one_hot = np.identity(self.camera_num)[tmp]\n",
    "#                     print(a_one_hot)\n",
    "#                     test = np.append(test, [a_one_hot], axis=0)\n",
    "#             print(test.shape)\n",
    "#             np.save(data_name, test)\n",
    "\n",
    "\n",
    "    \n",
    "#     def camera_return(self, num=0):\n",
    "#         if(num<self.camera_num):\n",
    "#             return num\n",
    "#         else:\n",
    "#             return num-self.camera_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
