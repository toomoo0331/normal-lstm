{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape, BatchNormalization, Add\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連x_test\n",
    "num_sample=3752 #画像の総フレーム数\n",
    "timesteps=30 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "\n",
    "#画像関連\n",
    "channels=3\n",
    "img_width=50\n",
    "img_height=50\n",
    "\n",
    "# LSTMなどで用いる値\n",
    "n_hidden = 256    # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 5   # バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, camera_num, file_name, samples, timesteps, width, height):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=samples\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.learnData=[]\n",
    "        self.labelData=[]\n",
    "        self.make_csvdata()\n",
    "        self.make_selection()\n",
    "    \n",
    "    def make_selection(self):\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        one_hot = np.eye(self.camera_num)\n",
    "        for row2 in csv_selection:\n",
    "            self.labelData.append(one_hot[int(row2[1])])\n",
    "    \n",
    "    \n",
    "    def make_csvdata(self):\n",
    "        for i in range(0, self.camera_num):\n",
    "            csv_selection=csv.reader(open(self.file_name+\"video/head.csv\", 'r'))\n",
    "            img_list=[]\n",
    "            for row2 in csv_selection:\n",
    "                img_list.append([row2[i]])\n",
    "            print(i)\n",
    "            self.learnData.append(img_list)\n",
    "        arr_multi = np.array(self.learnData)\n",
    "        print(arr_multi.shape)\n",
    "    \n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        test=[]\n",
    "        for i in range(0,self.samples-self.timesteps):\n",
    "            tmp_list=[]\n",
    "            for j in range(0, self.timesteps):\n",
    "                tmp_list.append(self.learnData[num][i+j])\n",
    "            test.append(tmp_list)\n",
    "        tmp_list=np.array(test)\n",
    "        tmp_list=tmp_list.astype(np.float)\n",
    "                \n",
    "        return tmp_list\n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        test=[]\n",
    "        for i in range(self.timesteps,self.samples):\n",
    "            test.append(self.labelData[i])\n",
    "        tmp_list = np.array(test)\n",
    "        tmp_list = tmp_list.astype(np.float)\n",
    "        \n",
    "        return tmp_list\n",
    "    \n",
    "    def show(self):\n",
    "        print(self.get_learndata(1).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "(5, 3752, 1)\n",
      "(3722, 30, 1)\n",
      "(3722, 5)\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(camera, \"./\", num_sample, timesteps, img_width, img_height)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18 :\n",
    "    ##\n",
    "    ##　Resnet-18の作成\n",
    "    ##\n",
    "    def __init__(self, width, height, channels):\n",
    "        self.img_rows=height\n",
    "        self.img_cols=width\n",
    "        self.img_channels=channels\n",
    "    \n",
    "    def rescell(self, data, filters, kernel_size, option=False):\n",
    "        strides=(1,1)\n",
    "        if option:\n",
    "            strides=(2,2)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        data=Convolution2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Add()([x,data])\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def create_resnet18(self):\n",
    "        inputs=Input(shape=(self.img_rows, self.img_cols, self.img_channels))\n",
    "        x=Convolution2D(64,(7,7), padding=\"same\", input_shape=(self.img_rows, self.img_cols),activation=\"relu\")(inputs)\n",
    "        x=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,128,(3,3),True)\n",
    "        x=self.rescell(x,128,(3,3))\n",
    "\n",
    "        x=self.rescell(x,256,(3,3),True)\n",
    "        x=self.rescell(x,256,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,512,(3,3),True)\n",
    "        x=self.rescell(x,512,(3,3))\n",
    "        \n",
    "        model=Model(inputs=inputs,outputs=[x])\n",
    "        return model\n",
    "\n",
    "    def get_resnet18(self):\n",
    "        return self.create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_hidden, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.resnet = Resnet18(width, height, 3).get_resnet18()\n",
    "        self.sharedLayer = self.create_sharedmodel()\n",
    "    \n",
    "    def create_sharedmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, 1))\n",
    "        \n",
    "        predictions = LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, 1),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(inputs)\n",
    "        \n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_layers\")\n",
    "        \n",
    "        return shared_layers\n",
    "    \n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, 1))\n",
    "        model_input2 = Input(shape=(self.maxlen, 1))\n",
    "        model_input3 = Input(shape=(self.maxlen, 1))\n",
    "        model_input4 = Input(shape=(self.maxlen, 1))\n",
    "        model_input5 = Input(shape=(self.maxlen, 1))\n",
    "        \n",
    "        mid_feature1 = self.sharedLayer(model_input1)\n",
    "        mid_feature2 = self.sharedLayer(model_input2)\n",
    "        mid_feature3 = self.sharedLayer(model_input3)\n",
    "        mid_feature4 = self.sharedLayer(model_input4)\n",
    "        mid_feature5 = self.sharedLayer(model_input5)\n",
    "        \n",
    "        merged_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=-1)\n",
    "        \n",
    "        mid_dense = Dense(self.n_hidden, activation='sigmoid')(merged_vector)\n",
    "        predictions = Dense(self.n_out, activation='softmax')(mid_dense)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], outputs=predictions)\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train1, x_train2, x_train3, x_train4, x_train5, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train1, x_train2, x_train3, x_train4, x_train5], t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "                         callbacks = [early_stopping], validation_split = 0.3)\n",
    "        return model, hist\n",
    "    \n",
    "    def train_keras(self, x_train1, x_train2, x_train3, x_train4, x_train5, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train1, x_train2, x_train3, x_train4, x_train5], t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "                         callbacks = [early_stopping], validation_split = 0.3)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 30, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_layers (Model)           (None, 256)          264192      input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1280)         0           shared_layers[1][0]              \n",
      "                                                                 shared_layers[2][0]              \n",
      "                                                                 shared_layers[3][0]              \n",
      "                                                                 shared_layers[4][0]              \n",
      "                                                                 shared_layers[5][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          327936      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            1285        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 593,413\n",
      "Trainable params: 593,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2605 samples, validate on 1117 samples\n",
      "Epoch 1/100\n",
      "2605/2605 [==============================] - 134s 52ms/step - loss: 0.3817 - acc: 0.8385 - val_loss: 0.6266 - val_acc: 0.6788\n",
      "Epoch 2/100\n",
      "2605/2605 [==============================] - 133s 51ms/step - loss: 0.3776 - acc: 0.8425 - val_loss: 0.6025 - val_acc: 0.6788\n",
      "Epoch 3/100\n",
      "2605/2605 [==============================] - 124s 47ms/step - loss: 0.3779 - acc: 0.8429 - val_loss: 0.6304 - val_acc: 0.6788\n",
      "Epoch 4/100\n",
      "2605/2605 [==============================] - 131s 50ms/step - loss: 0.3777 - acc: 0.8438 - val_loss: 0.5798 - val_acc: 0.6788\n",
      "Epoch 5/100\n",
      "2605/2605 [==============================] - 133s 51ms/step - loss: 0.3779 - acc: 0.8434 - val_loss: 0.6499 - val_acc: 0.6788\n",
      "Epoch 6/100\n",
      "2605/2605 [==============================] - 136s 52ms/step - loss: 0.3778 - acc: 0.8433 - val_loss: 0.6230 - val_acc: 0.6788\n",
      "Epoch 7/100\n",
      "2605/2605 [==============================] - 134s 52ms/step - loss: 0.3767 - acc: 0.8441 - val_loss: 0.5242 - val_acc: 0.8000\n",
      "Epoch 8/100\n",
      "2605/2605 [==============================] - 135s 52ms/step - loss: 0.3758 - acc: 0.8430 - val_loss: 0.5581 - val_acc: 0.6788\n",
      "Epoch 9/100\n",
      "2605/2605 [==============================] - 133s 51ms/step - loss: 0.3755 - acc: 0.8441 - val_loss: 0.5792 - val_acc: 0.6788\n",
      "Epoch 10/100\n",
      "2605/2605 [==============================] - 134s 52ms/step - loss: 0.3737 - acc: 0.8444 - val_loss: 0.5723 - val_acc: 0.6788\n",
      "Epoch 11/100\n",
      "2605/2605 [==============================] - 137s 52ms/step - loss: 0.3745 - acc: 0.8445 - val_loss: 0.5774 - val_acc: 0.6788\n",
      "Epoch 12/100\n",
      "2605/2605 [==============================] - 134s 52ms/step - loss: 0.3741 - acc: 0.8443 - val_loss: 0.5845 - val_acc: 0.6788\n",
      "Epoch 00012: early stopping\n",
      "3722/3722 [==============================] - 70s 19ms/step\n",
      "score: [0.43379129957425727, 0.7947340251328419]\n",
      "正答率: 0.48683503492745833\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "model , hist = pred.train(data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4), \n",
    "                                data.get_labeldata(), batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)], \n",
    "                                data.get_labeldata(), batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "pre = [[0 for i in range(5)] for j in range(5)]\n",
    "# 正答率集計\n",
    "preds = model.predict([data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4)])\n",
    "correct = 0\n",
    "\n",
    "f = open(\"./video/result_li.csv\", 'w')\n",
    "writer = csv.writer(f)\n",
    "for i in range(0,timesteps):\n",
    "    writer.writerow([0])\n",
    "        \n",
    "for i in range(len(preds)):\n",
    "    pred_result = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(data.get_labeldata()[i,:])\n",
    "    writer.writerow([pred_result])\n",
    "    pre[pred_result][tar]+=1\n",
    "    if pred_result == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,0,0,0,0]\n",
    "for()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
