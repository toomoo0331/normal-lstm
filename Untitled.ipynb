{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連\n",
    "num_sample=20 #画像の総フレーム数\n",
    "timesteps=5 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "#画像関連\n",
    "channels=3\n",
    "img_width=256\n",
    "img_height=256\n",
    "\n",
    "# LSTMなどで用いる値\n",
    "n_hidden = 256    # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 5   # ミニバッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_hidden, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.sharedLayer = self.create_sharedmodel()\n",
    "    \n",
    "    def create_sharedmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        x = TimeDistributed(Convolution2D(32, (3, 3), activation=\"relu\", padding=\"same\"))(inputs)\n",
    "        x = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "        x = TimeDistributed(Convolution2D(32, (3, 3), activation=\"relu\", padding=\"same\"))(x)\n",
    "        x = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x)\n",
    "        x = TimeDistributed(Dropout(0.25))(x)\n",
    "        x = TimeDistributed(Flatten())(x)\n",
    "        x = TimeDistributed(Dense(512))(x)\n",
    "        predictions = LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, 35),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(x)\n",
    "        #predictions = Dense(256, activation = \"softmax\", name=\"time_distr_dense_one\")(x)\n",
    "        \n",
    "        shared_layers = Network(inputs, predictions, name=\"shared_layers\")\n",
    "        \n",
    "        return shared_layers\n",
    "    \n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input2 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input3 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input4 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input5 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        mid_feature1 = self.sharedLayer(model_input1)\n",
    "        mid_feature2 = self.sharedLayer(model_input2)\n",
    "        mid_feature3 = self.sharedLayer(model_input3)\n",
    "        mid_feature4 = self.sharedLayer(model_input4)\n",
    "        mid_feature5 = self.sharedLayer(model_input5)\n",
    "        \n",
    "        merged_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=-1)\n",
    "        \n",
    "        predictions = Dense(self.n_out, activation='sigmoid')(merged_vector)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], outputs=predictions)\n",
    "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, x_train1, x_train2, x_train3, x_train4, x_train5, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train1, x_train2, x_train3, x_train4, x_train5], t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "              shuffle = True, callbacks = [early_stopping], validation_split = 0.3)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, camera_num, file_name, samples, timesteps, width, height):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=samples\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.learnData=[]\n",
    "        self.labelData=[]\n",
    "        \n",
    "        self.make_selection()\n",
    "        self.make_image()\n",
    "    \n",
    "    def make_selection(self):\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        one_hot = np.eye(self.camera_num)\n",
    "        for row2 in csv_selection:\n",
    "            self.labelData.append(one_hot[int(row2[1])])\n",
    "    \n",
    "    def make_image(self):\n",
    "        for i in range(0, self.camera_num):\n",
    "            img_list=[]\n",
    "            for j in range(0,self.samples):\n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/self.samples)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / self.samples * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "                file_path = \"image/\"+str(i)+\"/\"+str(j)+\".jpg\"\n",
    "                img = Image.open(file_path).convert('RGB') ## Gray->L, RGB->RGB\n",
    "                img = img.resize((self.width, self.height))\n",
    "                x = np.array(img, dtype=np.float32)\n",
    "                x = x / 255.\n",
    "                \n",
    "                img_list.append(x)\n",
    "            self.learnData.append(img_list)\n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        test=[]\n",
    "        for i in range(0,self.samples-self.timesteps):\n",
    "            tmp_list=[]\n",
    "            for j in range(0, self.timesteps):\n",
    "                tmp_list.append(self.learnData[num][i+j])\n",
    "            test.append(tmp_list)\n",
    "        tmp=np.array(test)\n",
    "        tmp=tmp.astype(np.float)\n",
    "                \n",
    "        return tmp\n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        test=[]\n",
    "        for i in range(self.timesteps,self.samples):\n",
    "            test.append(self.labelData[i])\n",
    "        tmp = np.array(test)\n",
    "        tmp = tmp.astype(np.float)\n",
    "        \n",
    "        return tmp\n",
    "    \n",
    "    def show(self):\n",
    "        print()\n",
    "        print(self.get_learndata(0).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [=================== ] 95.000000%\n",
      "(15, 5, 256, 256, 3)\n",
      "(15, 5)\n"
     ]
    }
   ],
   "source": [
    "data = Data(camera, \"./\", num_sample, timesteps, img_width, img_height)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 32    # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 5   # ミニバッチサイズ\n",
    "\n",
    "# モデル定義\n",
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "# 学習\n",
    "model , hist = pred.train(data.get_learndata(0),data.get_learndata(1),data.get_learndata(2),data.get_learndata(3),data.get_learndata(4), \n",
    "                                data.get_labeldata(), batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate(x_train, t_train, batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "pre = [[0 for i in range(3)] for j in range(3)]\n",
    "# 正答率集計\n",
    "preds = model.predict(x_test)\n",
    "correct = 0\n",
    "for i in range(len(preds)):\n",
    "    pred = np.argmax(preds[i,:])\n",
    "    tar = np.argmax(t_test[i,:])\n",
    "    pre[pred][tar]+=1\n",
    "    if pred == tar :\n",
    "        correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = Prediction(timesteps, n_hidden, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
