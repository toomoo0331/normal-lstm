{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape, BatchNormalization, Add, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.network import Network\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "from keras.initializers import glorot_normal,orthogonal\n",
    "\n",
    "from keras.callbacks import EarlyStopping,TensorBoard\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# sess = tf.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#どんくらいで学習させるか関連\n",
    "timesteps=10 #一回のLSTMに入れる値の数\n",
    "camera=5 #カメラの数\n",
    "\n",
    "rate = 10 #飛ばすフレーム数（30FPSを30/rateのFPSの動画に疑似変換する．）\n",
    "\n",
    "#画像関連 \n",
    "channels=3\n",
    "img_width=50\n",
    "img_height=50\n",
    "\n",
    "#LSTMなどで用いる値\n",
    "epochs = 100 # エポック数 \n",
    "batch_size = 5 # バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, camera_num, file_name, timesteps, width, height):\n",
    "        self.camera_num = camera_num\n",
    "        self.file_name =file_name\n",
    "        self.samples=0\n",
    "        self.timesteps=timesteps\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.save_numpy()\n",
    "        \n",
    "    def save_numpy(self):\n",
    "        self.samples = int(self.get_sample()/rate)\n",
    "        if not (os.path.isfile(self.file_name+\"train/label_\"+str(rate)+\".npy\")):\n",
    "            self.make_numpy_learnData()\n",
    "            self.make_numpy_labelData()\n",
    "        self.learnData=np.load(self.file_name+\"train/learn_\"+str(rate)+\".npy\")\n",
    "        self.labelData=np.load(self.file_name+\"train/label_\"+str(rate)+\".npy\")\n",
    "    \n",
    "    def get_sample(self):\n",
    "        video_path = self.file_name+\"video/0.mp4\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        num = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        return num\n",
    "    \n",
    "    def make_numpy_labelData(self):\n",
    "        labelData=[[],[],[],[],[]]\n",
    "        test=[0,0,0,0,0]\n",
    "        csv_selection=csv.reader(open(self.file_name+\"video/mintime_optimize.csv\", 'r'))\n",
    "        for i,row2 in enumerate(csv_selection):\n",
    "            if(i%rate==0 and i > (self.timesteps-1)*rate-1):\n",
    "                for j in range(self.camera_num):\n",
    "                    if j == int(row2[1]):\n",
    "                        labelData[j].append([1])\n",
    "                    else:\n",
    "                        labelData[j].append([0])\n",
    "                test[int(row2[1])]+=1\n",
    "        \n",
    "        \n",
    "        tmp_list = np.array(labelData)\n",
    "        tmp_list = tmp_list.astype(np.float)\n",
    "        np.save(self.file_name+\"train/label_\"+str(rate)+\".npy\", tmp_list)\n",
    "        print(tmp_list.shape)\n",
    "        print(test)\n",
    "    \n",
    "    \n",
    "    def make_numpy_learnData(self):\n",
    "        learnData=[]\n",
    "        for i in range(0, self.camera_num):\n",
    "            print()\n",
    "            img_list=[]\n",
    "            video_path = self.file_name+\"video/\"+str(i)+\".mp4\"\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            for j in range(0,video_len):\n",
    "                \n",
    "                pro_size=20\n",
    "                bar = int(j*pro_size/video_len)\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(j / video_len * 100.)\n",
    "                print('\\r{0}/{1} [{2}] {3}%'.format((i+1), self.camera_num, pro_bar, percent), end='')\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "                if(j%rate==0):\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    img=Image.fromarray(frame)\n",
    "                    img = img.resize((self.width, self.height))\n",
    "                    x = np.array(img, dtype=np.float32)\n",
    "                    x = x / 255.\n",
    "                    img_list.append(x)\n",
    "            learnData.append(img_list)\n",
    "            \n",
    "        tmp_list=np.array(learnData)\n",
    "        tmp_list=tmp_list.astype(np.float)\n",
    "        np.save(self.file_name+\"train/learn_\"+str(rate)+\".npy\", tmp_list)\n",
    "        print(tmp_list.shape)\n",
    "\n",
    "\n",
    "    def make_learndata(self):\n",
    "        data_name=self.file_name+\"train/learn_0_\"+str(rate)+\".npy\"\n",
    "        if (os.path.isfile(data_name)):\n",
    "            test=np.load(data_name)\n",
    "        else:\n",
    "            all_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "            tmp_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "            for i in range(0, self.labelData.shape[1]):\n",
    "                #まずはすべての分だけ回す\n",
    "                pro_size=20\n",
    "                bar = int(i*pro_size/self.labelData.shape[1])\n",
    "                pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "                percent ='{:03f}'.format(i / self.labelData.shape[1] * 100.)\n",
    "                print('\\r [{0}] {1}%'.format(pro_bar, percent), end='')\n",
    "\n",
    "                for camera in range(0, self.camera_num):\n",
    "                    #カメラの台数だけ回す\n",
    "                    #tmp_list[camera]の同じ引数（番号）には同じ時間軸のsequenceが入っている．\n",
    "                    first_list =np.empty((0, self.width, self.height, 3), np.float)\n",
    "                    for l in range(0, self.timesteps):\n",
    "                        #timesteps分のndarrayを作る．\n",
    "                        img=self.learnData[camera,i+l]\n",
    "                        first_list =np.append(first_list, [img], axis=0)\n",
    "                    #あるカメラについて，１つのsequenceがfirst_listに出来上がっている状態．\n",
    "                    tmp_list[camera]=np.append(tmp_list[camera], [first_list], axis=0)\n",
    "\n",
    "\n",
    "                if(tmp_list[0].shape[0]>100 or i == self.labelData.shape[1]-1):\n",
    "                    #処理時間短縮のため，sequenceがtmp_listに溜まってきたら，全体に統合してまたtmp_listを初期化する．\n",
    "                    for camera in range(0, self.camera_num):\n",
    "                        all_list[camera]=np.append(all_list[camera], tmp_list[camera], axis=0)\n",
    "                        tmp_list[camera] = np.empty((0,self.timesteps, self.width, self.height, 3), np.float)\n",
    "            \n",
    "            for camera in range(0, self.camera_num):\n",
    "                data_name=self.file_name+\"train/learn_\"+str(camera)+\"_\"+str(rate)\n",
    "                np.save(data_name, all_list[camera])\n",
    "    \n",
    "    \n",
    "    def make_labeldata(self):\n",
    "        data_name=self.file_name+\"train/final_label_\"+str(rate)+\"_.npy\"\n",
    "        if (os.path.isfile(data_name)):\n",
    "            test=np.load(data_name)\n",
    "        else:\n",
    "            np.save(data_name, self.labelData)\n",
    "    \n",
    "    \n",
    "    def get_learndata(self, num):\n",
    "        data_name=self.file_name+\"train/learn_\"+str(num)+\"_\"+str(rate)+\".npy\"\n",
    "        test=np.load(data_name)\n",
    "        return test\n",
    "    \n",
    "    \n",
    "    def get_labeldata(self):\n",
    "        data_name=self.file_name+\"train/final_label_\"+str(rate)+\"_.npy\"\n",
    "        test=np.load(data_name)\n",
    "        return test\n",
    "    \n",
    "    \n",
    "    def show(self):\n",
    "        print(0,self.get_learndata(0).shape)\n",
    "        print(1,self.get_learndata(1).shape)\n",
    "        print(2,self.get_learndata(2).shape)\n",
    "        print(3,self.get_learndata(3).shape)\n",
    "        print(4,self.get_learndata(4).shape)\n",
    "        print(self.get_labeldata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = DataLoader(camera, \"./data/20190427/\", timesteps, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=================== ] 99.444444%"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1620 is out of bounds for axis 1 with size 1620",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ea79331f884a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_learndata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_labeldata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8683f110a503>\u001b[0m in \u001b[0;36mmake_learndata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                         \u001b[0;31m#timesteps分のndarrayを作る．\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearnData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                         \u001b[0mfirst_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0;31m#あるカメラについて，１つのsequenceがfirst_listに出来上がっている状態．\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1620 is out of bounds for axis 1 with size 1620"
     ]
    }
   ],
   "source": [
    "data.make_learndata()\n",
    "data.make_labeldata()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18 :\n",
    "    ##\n",
    "    ##　Resnet-18の作成\n",
    "    ##\n",
    "    def __init__(self, width, height, channels):\n",
    "        self.img_rows=height\n",
    "        self.img_cols=width\n",
    "        self.img_channels=channels\n",
    "    \n",
    "    def rescell(self, data, filters, kernel_size, option=False):\n",
    "        strides=(1,1)\n",
    "        if option:\n",
    "            strides=(2,2)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        data=Convolution2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
    "        x=Convolution2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
    "        x=BatchNormalization()(x)\n",
    "        x=Add()([x,data])\n",
    "        x=Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def create_resnet18(self):\n",
    "        inputs=Input(shape=(self.img_rows, self.img_cols, self.img_channels))\n",
    "        x=Convolution2D(64,(7,7), padding=\"same\", input_shape=(self.img_rows, self.img_cols),activation=\"relu\")(inputs)\n",
    "        x=MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        x=self.rescell(x,64,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,128,(3,3),True)\n",
    "        x=self.rescell(x,128,(3,3))\n",
    "\n",
    "        x=self.rescell(x,256,(3,3),True)\n",
    "        x=self.rescell(x,256,(3,3))\n",
    "        \n",
    "        x=self.rescell(x,512,(3,3),True)\n",
    "        x=self.rescell(x,512,(3,3))\n",
    "        \n",
    "        model=Model(inputs=inputs,outputs=[x])\n",
    "        return model\n",
    "\n",
    "    def get_resnet18(self):\n",
    "        return self.create_resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    def __init__(self, timesteps, n_out, width, height):\n",
    "        self.maxlen = timesteps\n",
    "        self.n_out = n_out\n",
    "        self.width=width\n",
    "        self.height=height\n",
    "        self.resnet = Resnet18(width, height, 3).get_resnet18()\n",
    "        self.sharedLSTMmodel = self.create_sharedLSTMmodel()\n",
    "        self.sharedRateModel = self.create_sharedRatemodel()\n",
    "    \n",
    "    \n",
    "    def create_sharedLSTMmodel(self):\n",
    "        inputs = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        x = TimeDistributed(self.resnet,name=\"resnet\")(inputs)\n",
    "        x = TimeDistributed(GlobalAveragePooling2D(), name=\"GAP\")(x)\n",
    "        x = TimeDistributed(Dense(512,activation='relu'), name=\"dense\")(x)\n",
    "        predictions = LSTM(256, batch_input_shape = (None, self.maxlen, 512),\n",
    "             kernel_initializer = glorot_normal(seed=20181020),\n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20181020), \n",
    "             dropout = 0.01, \n",
    "             recurrent_dropout = 0.01)(x)\n",
    "        \n",
    "        predictions =Reshape((1,256))(predictions)\n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_LSTMlayers\")\n",
    "        return shared_layers\n",
    "    \n",
    "    \n",
    "    def create_sharedRatemodel(self):\n",
    "        inputs = Input(shape=(512,))\n",
    "        mid_dense = Dense(256, activation='relu')(inputs)\n",
    "        predictions = Dense(1, activation='sigmoid')(mid_dense)\n",
    "        shared_layers = Model(inputs, predictions, name=\"shared_Ratelayers\")\n",
    "        return shared_layers\n",
    "\n",
    "\n",
    "    def create_model(self):\n",
    "        model_input1 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input2 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input3 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input4 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        model_input5 = Input(shape=(self.maxlen, self.height, self.width, 3))\n",
    "        \n",
    "        mid_feature1 = self.sharedLSTMmodel(model_input1)\n",
    "        mid_feature2 = self.sharedLSTMmodel(model_input2)\n",
    "        mid_feature3 = self.sharedLSTMmodel(model_input3)\n",
    "        mid_feature4 = self.sharedLSTMmodel(model_input4)\n",
    "        mid_feature5 = self.sharedLSTMmodel(model_input5)\n",
    "        \n",
    "        \n",
    "        pooling_vector = keras.layers.concatenate([mid_feature1, mid_feature2, mid_feature3, mid_feature4, mid_feature5], axis=1)\n",
    "        pooling_vector = MaxPooling1D(pool_size=camera)(pooling_vector)\n",
    "        \n",
    "        \n",
    "        merge_feature1 = keras.layers.concatenate([mid_feature1, pooling_vector], axis=-1)\n",
    "        merge_feature2 = keras.layers.concatenate([mid_feature2, pooling_vector], axis=-1)\n",
    "        merge_feature3 = keras.layers.concatenate([mid_feature3, pooling_vector], axis=-1)\n",
    "        merge_feature4 = keras.layers.concatenate([mid_feature4, pooling_vector], axis=-1)\n",
    "        merge_feature5 = keras.layers.concatenate([mid_feature5, pooling_vector], axis=-1)\n",
    "        \n",
    "        merge_feature1 = Reshape((512,))(merge_feature1)\n",
    "        merge_feature2 = Reshape((512,))(merge_feature2)\n",
    "        merge_feature3 = Reshape((512,))(merge_feature3)\n",
    "        merge_feature4 = Reshape((512,))(merge_feature4)\n",
    "        merge_feature5 = Reshape((512,))(merge_feature5)\n",
    "        \n",
    "        predictions1 = self.sharedRateModel(merge_feature1)\n",
    "        predictions2 = self.sharedRateModel(merge_feature2)\n",
    "        predictions3 = self.sharedRateModel(merge_feature3)\n",
    "        predictions4 = self.sharedRateModel(merge_feature4)\n",
    "        predictions5 = self.sharedRateModel(merge_feature5)\n",
    "        \n",
    "        model = Model(inputs=[model_input1, model_input2, model_input3, model_input4, model_input5], \n",
    "                      outputs=[predictions1,predictions2,predictions3,predictions4,predictions5])\n",
    "        model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def train(self, x_train, t_train, x_vali, t_vali, batch_size, epochs):\n",
    "        early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit(x=[x_train[0], x_train[1], x_train[2], x_train[3], x_train[4]], y=t_train, batch_size = batch_size,\n",
    "                         epochs = epochs, validation_data=([x_vali[0], x_vali[1], x_vali[2], x_vali[3], x_vali[4]], t_vali),\n",
    "                         callbacks = [early_stopping])\n",
    "        return model, hist\n",
    "    \n",
    "    \n",
    "    def train_keras(self, x_train, t_train, batch_size, epochs):\n",
    "        early_stopping = EarlyStopping(patience=20, verbose=1)\n",
    "        model = self.create_model()\n",
    "        hist = model.fit([x_train[0], x_train[1], x_train[2], x_train[3], x_train[4]], \n",
    "                         [t_train[0], t_train[1], t_train[2], t_train[3], t_train[4]],\n",
    "                         batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "                         callbacks = [early_stopping], validation_split = 0.2)\n",
    "        return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "pred = Prediction(timesteps, camera, img_width, img_height)\n",
    "model = pred.create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "train_learn=[np.empty((data.get_labeldata().shape[0],10, 50, 50, 3), np.float)]*camera\n",
    "vali_learn=[np.empty((0,10, 50, 50, 3), np.float)]*camera\n",
    "train_label=data.get_labeldata()\n",
    "vali_label=np.empty((0,camera), np.float)\n",
    "\n",
    "print(train_label.shape)\n",
    "\n",
    "for j in range(0,camera):\n",
    "    train_learn[j]=data.get_learndata(j)\n",
    "\n",
    "# for i in tqdm(range(0,int(0.1*test_label.shape[0]))):\n",
    "#     random_angle = int(random.randint(0,test_label.shape[0]-1))\n",
    "#     for j in range(0,camera):\n",
    "#         vali_learn[j]=np.append(vali_learn[j], [test_learn[j][random_angle]],axis=0)\n",
    "#         test_learn[j]=np.delete(test_learn[j], random_angle,0)\n",
    "#     vali_label=np.append(vali_label, [test_label[random_angle]], axis=0)\n",
    "#     test_label=np.delete(test_label, random_angle,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "#model , hist = pred.train(test_learn, test_label, vali_learn, vali_label, batch_size, epochs)\n",
    "model , hist = pred.train_keras(train_learn, train_label, batch_size, epochs)\n",
    "# テスト\n",
    "#score = model.evaluate(test_learn, test_label, batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model):\n",
    "    for i in model.layers:\n",
    "        i.trainable = False\n",
    "        if isinstance(i, Model):\n",
    "            freeze_layers(i)\n",
    "    return model\n",
    "\n",
    "model_freezed = freeze_layers(model)\n",
    "model_freezed.save('model/file0206.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_loss(hist):\n",
    "    # 損失値(Loss)の遷移のプロット\n",
    "    plt.plot(hist.history['loss'],label=\"loss for training\")\n",
    "    plt.plot(hist.history['val_loss'],label=\"loss for validation\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_history_acc(hist):\n",
    "    # 精度(Accuracy)の遷移のプロット\n",
    "    plt.plot(hist.history['acc'],label=\"loss for training\")\n",
    "    plt.plot(hist.history['val_acc'],label=\"loss for validation\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()\n",
    "\n",
    "plot_history_loss(hist)\n",
    "plot_history_acc(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カメラ番号をランダムに並び替えることでデータの偏りをなくそうというデータ作成プログラム\n",
    "\n",
    "\n",
    "# def make_learndata(self):\n",
    "#         data_name=self.file_name+\"learn_0_\"+str(rate)+\".npy\"\n",
    "#         if (os.path.isfile(data_name)):\n",
    "#             test=np.load(data_name)\n",
    "#         else:\n",
    "#             all_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "#             tmp_list = [np.empty((0,self.timesteps, self.width, self.height, 3), np.float)]*self.camera_num\n",
    "#             for i in range(0, self.labelData.shape[0]):\n",
    "#                 #まずはすべての分だけ回す\n",
    "#                 pro_size=20\n",
    "#                 bar = int(i*pro_size/self.labelData.shape[0])\n",
    "#                 pro_bar = ('=' * bar) + (' ' * (pro_size - bar))\n",
    "#                 percent ='{:03f}'.format(i / self.labelData.shape[0] * 100.)\n",
    "#                 print('\\r [{0}] {1}%'.format(pro_bar, percent), end='')\n",
    "                            \n",
    "#                 for j in range(0,self.camera_num):\n",
    "#                     for camera in range(0, self.camera_num):\n",
    "#                         #カメラの台数だけ回す\n",
    "#                         #tmp_list[camera]の同じ引数（番号）には角度を同じ分だけずらした同じ時間軸のsequenceが入っている．\n",
    "#                         first_list =np.empty((0, self.width, self.height, 3), np.float)\n",
    "#                         for l in range(0, self.timesteps):\n",
    "#                             #timesteps分のndarrayを作る．\n",
    "#                             img=self.learnData[camera,i+l]\n",
    "#                             first_list =np.append(first_list, [img], axis=0)\n",
    "#                         #あるカメラについて，１つのsequenceがfirst_listに出来上がっている状態．\n",
    "#                         tmp_camera_num=self.camera_return(camera+j)\n",
    "#                         tmp_list[tmp_camera_num]=np.append(tmp_list[tmp_camera_num], [first_list], axis=0)\n",
    "    \n",
    "\n",
    "#                 if(tmp_list[0].shape[0]>100 or i == self.labelData.shape[0]-1):\n",
    "#                     #処理時間短縮のため，sequenceがtmp_listに溜まってきたら，全体に統合してまたtmp_listを初期化する．\n",
    "#                     for camera in range(0, self.camera_num):\n",
    "#                         all_list[camera]=np.append(all_list[camera], tmp_list[camera], axis=0)\n",
    "#                         tmp_list[camera] = np.empty((0,self.timesteps, self.width, self.height, 3), np.float)\n",
    "            \n",
    "#             for camera in range(0, self.camera_num):\n",
    "#                 print(all_list[camera].shape)\n",
    "#                 data_name=self.file_name+\"learn_\"+str(camera)+\"_\"+str(rate)\n",
    "#                 np.save(data_name, all_list[camera])\n",
    "    \n",
    "    \n",
    "#     def make_labeldata(self):\n",
    "#         data_name=self.file_name+\"final_label_\"+str(rate)+\"_.npy\"\n",
    "#         if (os.path.isfile(data_name)):\n",
    "#             test=np.load(data_name)\n",
    "#         else:\n",
    "#             test = np.empty((0,self.camera_num), np.float)\n",
    "#             for i in range(0,self.labelData.shape[0]):\n",
    "#                 for j in range(0, self.camera_num):\n",
    "#                     tmp=self.camera_return(np.argmax(self.labelData[i])+j)\n",
    "#                     a_one_hot = np.identity(self.camera_num)[tmp]\n",
    "#                     print(a_one_hot)\n",
    "#                     test = np.append(test, [a_one_hot], axis=0)\n",
    "#             print(test.shape)\n",
    "#             np.save(data_name, test)\n",
    "\n",
    "\n",
    "    \n",
    "#     def camera_return(self, num=0):\n",
    "#         if(num<self.camera_num):\n",
    "#             return num\n",
    "#         else:\n",
    "#             return num-self.camera_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
